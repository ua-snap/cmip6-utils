{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5cc50df-ed13-409e-b2b8-0a6f59dc1c8b",
   "metadata": {},
   "source": [
    "# CMIP6 Deltas\n",
    "\n",
    "This notebook is for downloading monthly CMIP6 data and computing deltas. It is for an ad-hoc project to generate some useful CMIP6 summaries for Alaska while we await the infrastructure upgrades for accessing and working with larger amounts of data. The data downloaded here may be used in other efforts as well, such as statistical downscaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d4c0ad-3ca3-4dab-a3f4-fa3abb1127d9",
   "metadata": {},
   "source": [
    "# Download monthly CMIP6 data\n",
    "\n",
    "### Copernicus API\n",
    "\n",
    "This notebook will use the [Copernicus API](https://cds.climate.copernicus.eu/api-how-to#install-the-cds-api-key) to access data.\n",
    "\n",
    "The `cdsapi` python package will need to be installed, it is available via `pip` and on conda-forge: `conda install -c conda-forge cdsapi`. \n",
    "\n",
    "Credentials need to be placed in `$HOME/.cdsapirc` per the instructions at the link above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b79a349f-dc95-4ede-b4fb-4f4593e744a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - define all imports and paths\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import cdsapi\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "# download module\n",
    "import download\n",
    "\n",
    "\n",
    "base_dir = Path(os.getenv(\"BASE_DIR\") or \"/workspace/Shared/Tech_Projects/cmip6/project_data\")\n",
    "out_dir = Path(os.getenv(\"OUTPUT_DIR\") or \"/workspace/Shared/Tech_Projects/cmip6/final_products\")\n",
    "scratch_dir = Path(os.getenv(\"SCRATCH_DIR\") or \"/atlas_scratch/kmredilla/cmip6\")\n",
    "\n",
    "anc_dir = base_dir.joinpath(\"ancillary\")\n",
    "anc_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# tracking CSV filepath\n",
    "tracker_fp = anc_dir.joinpath(\"download_tracker.csv\")\n",
    "    \n",
    "# make directory for collecting text files for capturing\n",
    "# the cdsapi logs\n",
    "download_log_dir = scratch_dir.joinpath(\"download_logs\")\n",
    "download_log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# need main folder for raw data\n",
    "raw_dir = base_dir.joinpath(\"raw\")\n",
    "raw_dir.mkdir(exist_ok=True)\n",
    "# folders for met var data, for land surface data, and water balance data\n",
    "# meteorological data\n",
    "met_group_name = \"met_data\"\n",
    "met_dir = raw_dir.joinpath(met_group_name)\n",
    "met_dir.mkdir(exist_ok=True)\n",
    "# land surface data\n",
    "land_group_name = \"land_data\"\n",
    "land_dir = raw_dir.joinpath(land_group_name)\n",
    "land_dir.mkdir(exist_ok=True)\n",
    "# water balance data\n",
    "wb_group_name = \"water_balance_data\"\n",
    "wb_dir = raw_dir.joinpath(wb_group_name)\n",
    "wb_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203680e-1f4e-4e5f-b0a1-1820d9b0ce03",
   "metadata": {},
   "source": [
    "### Targets\n",
    "\n",
    "This section describes the various subsets of CMIP6 data we are interested in. There are three main groups:\n",
    "1. meterological data at monthly resolution (temp, precip, SLP)\n",
    "2. model data, for lack of a better term - data about the models\n",
    "3. water balance data at monthly resolution\n",
    "\n",
    "#### Meteorological data\n",
    "**Temporal resolution**: Monthly  \n",
    "**Experiment (4)**: Historical, SSP1-2.6, SSP2-4.5, SSP5-8.5  \n",
    "**Variable (3)**: Near-surface air temperature, Precipitation, Sea level pressure  \n",
    "**Model (12)**: ACCESS-CM2, CESM2, CNRM-CM6-1-HR, EC-Earth3-Veg-LR, GFDL-ESM4, HadGEM3-GC31-LL, HadGEM3-GC31-MM, KACE-1-0-G, MIROC6, MPI-ESM1-2-LR, MRI-ESM2-0, NorESM2-MM  \n",
    "\n",
    "\n",
    "#### Land surface data\n",
    "**Temporal resolution**: Fixed (no temporal resolution)  \n",
    "**Experiment (1)**: Historical  \n",
    "**Variable (3)**: Surface altitude, Percentage of the grid cell occupied by land including lakes, Sea area percentage  \n",
    "**Model (?)**: Subset of above, available  \n",
    "\n",
    "#### Water balance data\n",
    "**Temporal resolution**: Monthly  \n",
    "**Experiment (3)**: Historical, SSP2-4.5, SSP5-8.5  \n",
    "**Variable (5)**: Evaporation including sublimation and transpiration, Moisture in upper portion of soil column, snowfall flux, surface snow amount, total runoff  \n",
    "**Model (6)**: CESM2, EC-Earth3-Veg-LR, GFDL-ESM4, MIROC6, MRI-ESM2-0, NorESM2-MM  \n",
    "\n",
    "#### Fixed parameters\n",
    "For all of these groups, the following parameters will be constant:  \n",
    "**Level (1)**: single levels   \n",
    "**Geographical Area**: Sub-region extraction, North: 74, South 50, West 174, East -120   \n",
    "**Temporal subset**: Whole available temporal range  \n",
    "\n",
    "\n",
    "### Notes for downloading\n",
    "\n",
    "Here are some notes for downloading based on preliminary explorations:  \n",
    "\n",
    "* the CDS API does not support queries across the antimeridian so there will need to be two bounding boxes queried and then mosaicked together:\n",
    "    1. (174, 50, 180, 74)\n",
    "    2. (-180, 50, -120, 74)\n",
    "* the CDS API does not support multiple values for a given field and so requests should be broken up by model, scenario (experiment), and variable\n",
    "* the longitude coordiantes for \"sea area percentage\" seem to be on a strictly positive axis (0, 360) and the positive bbox of the above (74, 174, 50, 240) causes errors, so we might just need to grab the whole grid for these ones.\n",
    "\n",
    "See the Appendix section for some examples of the above issues.\n",
    "\n",
    "### Define targets in a tracking table\n",
    "\n",
    "Make a table for tracking the progress of downloads with the following columns:\n",
    "\n",
    "* `data_group`: which of the above groups the download is for, either `\"met_vars\"`, `\"land_surface\"`, or `\"water_balance\"`\n",
    "* `model`\n",
    "* `scenario`\n",
    "* `variable`\n",
    "* `t_res`: temporal resolution, either `\"monthly\"` or `\"fixed\"`\n",
    "* `bbox`: spatial extent, in form (N, W, S, E), should be either `(74, 174, 50, -120)` or `None` (for sea area percentage only)\n",
    "* `result`: download result, either `\"pass\"`, `\"fail\"`, or `None`\n",
    "* `fail_reason`: fail message where applicable, or `None`\n",
    "* `zip_path`: path to where downloaded `.zip` data in `$SCRATCH_DIR` should be written\n",
    "* `base_path`: Path to where data should be unzipped and placed in `$BASE_DIR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a5b68e9-5469-4b0e-b022-1a9c51639edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tracker - set to True to reset tracking spreadsheet\n",
    "reset_tracker = True\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# make the tracking dataframe\n",
    "column_names = [\n",
    "    \"data_group\",\n",
    "    \"model\",\n",
    "    \"scenario\",\n",
    "    \"variable\",\n",
    "    \"t_res\",\n",
    "    \"bbox\",\n",
    "    \"hemisphere\", # east or west\n",
    "    \"levels\",\n",
    "    \"format\",\n",
    "    \"result\",\n",
    "    \"fail_reason\",\n",
    "    \"zip_path\",\n",
    "    \"base_path\",\n",
    "    \"log_path\",\n",
    "]\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "if reset_tracker:\n",
    "    df.to_csv(tracker_fp, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f49e121-0a02-4ae6-85e3-c8ca7b0eb9f8",
   "metadata": {},
   "source": [
    "Start specifying the options for populating the table.\n",
    "\n",
    "##### Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb9c9fd-9016-485a-8d36-1065224bb6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a lookup dict for CDS API\n",
    "api_lu = {}\n",
    "\n",
    "# full names of models (for reference at this point)\n",
    "models = [\n",
    "    \"ACCESS-CM2\",\n",
    "    \"CESM2\",\n",
    "    \"CNRM-CM6-1-HR\",\n",
    "    \"EC-Earth3-Veg-LR\",\n",
    "    \"GFDL-ESM4\",\n",
    "    \"HadGEM3-GC31-LL\",\n",
    "    \"HadGEM3-GC31-MM\",\n",
    "    \"KACE-1-0-G\",\n",
    "    \"MIROC6\",\n",
    "    \"MPI-ESM1-2-LR\",\n",
    "    \"MRI-ESM2-0\",\n",
    "    \"NorESM2-MM\",\n",
    "]\n",
    "# api names for models are simply lower case and underscores instead of hyphens\n",
    "api_lu[\"models\"] = {model: model.lower().replace(\"-\", \"_\") for model in models}\n",
    "\n",
    "# subset of models for the water balanace data\n",
    "wb_models = [\n",
    "    \"CESM2\",\n",
    "    \"EC-Earth3-Veg-LR\",\n",
    "    \"GFDL-ESM4\",\n",
    "    \"MIROC6\",\n",
    "    \"MRI-ESM2-0\",\n",
    "    \"NorESM2-MM\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afde330-bc51-4f7b-b899-fb877d1d91a2",
   "metadata": {},
   "source": [
    "##### Scenarios (experiments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a17a5d31-60f9-4433-930e-c5711e895cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [\n",
    "    \"historical\",\n",
    "    \"SSP1-2.6\",\n",
    "    \"SSP2-4.5\",\n",
    "    \"SSP5-8.5\",\n",
    "]\n",
    "\n",
    "# water balance scenarios\n",
    "wb_scenarios = [\n",
    "    \"historical\",\n",
    "    \"SSP2-4.5\",\n",
    "    \"SSP5-8.5\",\n",
    "]\n",
    "\n",
    "# lookups for API\n",
    "api_lu[\"scenarios\"] = {\n",
    "    \"historical\": \"historical\",\n",
    "    \"SSP1-2.6\": \"ssp1_2_6\",\n",
    "    \"SSP2-4.5\": \"ssp2_4_5\",\n",
    "    \"SSP5-8.5\": \"ssp5_8_5\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252e753-89f7-4c9b-a19e-4ca9ff6bc4ed",
   "metadata": {},
   "source": [
    "##### Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44330cf-993d-4923-a0fd-1f4ce90717d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_varnames = [\"tas\", \"pr\", \"psl\"]\n",
    "land_varnames = [\"orog\", \"sftlf\", \"sftof\"]\n",
    "wb_varnames = [\"evspsbl\", \"mrsos\", \"prsn\", \"snw\", \"mrro\"]\n",
    "\n",
    "# variable names\n",
    "api_lu[\"varnames\"] = {\n",
    "    \"tas\": \"near_surface_air_temperature\",\n",
    "    \"pr\": \"precipitation\",\n",
    "    \"psl\": \"sea_level_pressure\",\n",
    "    \"orog\": \"surface_altitude\",\n",
    "    \"sftlf\": \"percentage_of_the_grid_cell_occupied_by_land_including_lakes\",\n",
    "    \"sftof\": \"sea_area_percentage\",\n",
    "    \"evspsbl\": \"evaporation_including_sublimation_and_transpiration\",\n",
    "    \"mrsos\": \"moisture_in_upper_portion_of_soil_column\",\n",
    "    \"prsn\": \"snowfall_flux\",\n",
    "    \"snw\": \"surface_snow_amount\",\n",
    "    \"mrro\": \"total_runoff\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2c8008-9e15-47a8-8280-c672c091aee4",
   "metadata": {},
   "source": [
    "##### Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cde844dd-a445-4738-8c78-706fd4497f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these will stay constant over most combinations\n",
    "# two bboxes, \"east\" one will be the one in the eastern hemisphere (west of dateline)\n",
    "bboxes = {\"west\": [74, -180, 50, -120], \"east\": [74, 174, 50, 180]}\n",
    "level = \"single_levels\"\n",
    "api_format = \"zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fad6d8-73bc-4b7e-b030-5200cd4f5ddb",
   "metadata": {},
   "source": [
    "Start populating the table:\n",
    "\n",
    "##### Met vars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79fdd6de-847d-46fe-9979-327653ced949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the df\n",
    "df = pd.read_csv(tracker_fp)\n",
    "\n",
    "monthly_zip_fn = \"{}_monthly_mean_{}_{}_{}.zip\"\n",
    "for model in models:\n",
    "    for scenario in scenarios:\n",
    "        for varname in met_varnames:\n",
    "            for bbox in bboxes:\n",
    "                row_df = {\n",
    "                    \"data_group\": met_group_name,\n",
    "                    \"model\": api_lu[\"models\"][model],\n",
    "                    \"scenario\": api_lu[\"scenarios\"][scenario],\n",
    "                    \"variable\": api_lu[\"varnames\"][varname],\n",
    "                    \"t_res\": \"monthly\",\n",
    "                    \"bbox\": bboxes[bbox],\n",
    "                    \"hemisphere\": bbox,\n",
    "                    \"levels\": level,\n",
    "                    \"format\": api_format,\n",
    "                    \"result\": None,\n",
    "                    \"fail_reason\": None,\n",
    "                    \"base_path\": None,\n",
    "                    \"zip_path\": scratch_dir.joinpath(\n",
    "                        monthly_zip_fn.format(varname, model, scenario, bbox)\n",
    "                    )\n",
    "                }\n",
    "                # make stdout_path for writing printed results of retrieve() function\n",
    "                row_df[\"log_path\"] = download_log_dir.joinpath(\n",
    "                    row_df[\"zip_path\"].name.replace(\".zip\", \"_download_log.txt\")\n",
    "                )\n",
    "                df = df.append(row_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c3c964-4641-484b-a0f7-84b3144501da",
   "metadata": {},
   "source": [
    "##### Land surface vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef26ff19-f4a7-4f8b-be74-d0fd3e526eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_zip_fn = \"{}_fx_{}_historical_{}.zip\"\n",
    "for model in models:\n",
    "    for varname in land_varnames:\n",
    "        for bbox in bboxes:\n",
    "            row_df = {\n",
    "                \"data_group\": land_group_name,\n",
    "                \"model\": api_lu[\"models\"][model],\n",
    "                \"scenario\": \"historical\",\n",
    "                \"variable\": api_lu[\"varnames\"][varname],\n",
    "                \"t_res\": \"fixed\",\n",
    "                \"bbox\": bboxes[bbox],\n",
    "                \"hemisphere\": bbox,\n",
    "                \"levels\": level,\n",
    "                \"format\": api_format,\n",
    "                \"result\": None,\n",
    "                \"fail_reason\": None,\n",
    "                \"base_path\": None,\n",
    "                \"zip_path\": scratch_dir.joinpath(\n",
    "                    land_zip_fn.format(varname, model, bbox)\n",
    "                )\n",
    "            }\n",
    "            # set the bbox to None if varname is sftof (sea area percentage)\n",
    "            if varname == \"sftof\":\n",
    "                row_df[\"bbox\"] = None\n",
    "            # make stdout_path for writing printed results of retrieve() function\n",
    "            row_df[\"log_path\"] = download_log_dir.joinpath(\n",
    "                row_df[\"zip_path\"].name.replace(\".zip\", \"_download_log.txt\")\n",
    "            )\n",
    "            df = df.append(row_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c68765-89f8-4eef-9483-4cd41a661d9d",
   "metadata": {},
   "source": [
    "##### Water balance vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a482b55-8022-40c5-8946-f97a753ea6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in wb_models:\n",
    "    for scenario in wb_scenarios:\n",
    "        for varname in wb_varnames:\n",
    "            for bbox in bboxes:\n",
    "                row_df = {\n",
    "                    \"data_group\": wb_group_name,\n",
    "                    \"model\": api_lu[\"models\"][model],\n",
    "                    \"scenario\": api_lu[\"scenarios\"][scenario],\n",
    "                    \"variable\": api_lu[\"varnames\"][varname],\n",
    "                    \"t_res\": \"monthly\",\n",
    "                    \"bbox\": bboxes[bbox],\n",
    "                    \"hemisphere\": bbox,\n",
    "                    \"levels\": level,\n",
    "                    \"format\": api_format,\n",
    "                    \"result\": None,\n",
    "                    \"fail_reason\": None,\n",
    "                    \"base_path\": None,\n",
    "                    \"zip_path\": scratch_dir.joinpath(\n",
    "                        monthly_zip_fn.format(varname, model, scenario, bbox)\n",
    "                    )\n",
    "                }\n",
    "                # make stdout_path for writing printed results of retrieve() function\n",
    "                row_df[\"log_path\"] = download_log_dir.joinpath(\n",
    "                    row_df[\"zip_path\"].name.replace(\".zip\", \"_download_log.txt\")\n",
    "                )\n",
    "                df = df.append(row_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ee33b-bb03-4b45-bb96-50a07764c9cf",
   "metadata": {},
   "source": [
    "Reset the index to get a unique ID for each row, and call that column \"id\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47b1b97f-bb39-41fe-bd37-28775a38ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().rename(columns={\"index\": \"id\"}).to_csv(tracker_fp, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404c2ce-358f-45d0-aa6b-c9824be7157e",
   "metadata": {},
   "source": [
    "### Run the downloads\n",
    "\n",
    "Attempt to download all combinations specified in each row in the tracker table via the CDS API. Do this in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcab89a1-7437-4673-9027-a7bf669e8fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 540/540 [1:14:58<00:00,  8.33s/it]\n"
     ]
    }
   ],
   "source": [
    "# load and update the tracker before trying to download anything\n",
    "df = download.update_tracker(tracker_fp, raw_dir)\n",
    "rows = [row[1].copy(deep=True) for row in df.iterrows()]\n",
    "\n",
    "with Pool(32) as pool:\n",
    "    new_rows = [\n",
    "        result for result in tqdm.tqdm(\n",
    "            pool.imap_unordered(download.download, rows), total=len(rows))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd023dbb-ed59-407c-8f3f-0a0319bbc4f8",
   "metadata": {},
   "source": [
    "Write results of downloading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a7bd32d1-e435-4206-beb8-75788cdeddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(new_rows).sort_values(\"id\")\n",
    "df.to_csv(tracker_fp, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1460c271-b87c-4237-b7ff-a865dc4ef121",
   "metadata": {},
   "source": [
    "Update the tracker after downloading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e105796a-b50a-4edf-b52d-c90753c367f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = download.update_tracker(tracker_fp, raw_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c6f60-a8b3-4a3a-960e-ec333d0388f9",
   "metadata": {},
   "source": [
    "Unzip files in batch and update tracker as this happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bec5081c-4af7-4234-a62b-41a863b48df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 data files extracted from zips\n"
     ]
    }
   ],
   "source": [
    "df = download.batch_unzip(tracker_fp, raw_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038b62b-18cc-4cbb-8493-db559f6a58e6",
   "metadata": {},
   "source": [
    "How many data files were successfully downloaded and extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bfd0800b-bece-45f0-bba0-23f91eba7e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meteorological data: 280 files\n",
      "Land surface data: 36 files\n",
      "Water balance data: 164 files\n"
     ]
    }
   ],
   "source": [
    "print(f\"Meteorological data: {len(list(met_dir.glob('*.nc')))} files\")\n",
    "print(f\"Land surface data: {len(list(land_dir.glob('*.nc')))} files\")\n",
    "print(f\"Water balance data: {len(list(wb_dir.glob('*.nc')))} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c7ccf1-80d8-4d5b-aced-f5b0fea7caa5",
   "metadata": {},
   "source": [
    "How many files would not unzip?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6bbc20f2-2925-49a2-bf76-528c7483d7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 failed extractions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_group</th>\n",
       "      <th>model</th>\n",
       "      <th>scenario</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [data_group, model, scenario, variable]\n",
       "Index: []"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = df[df[\"fail_reason\"] == \"BadZipFile\"]\n",
    "print(f\"{len(temp_df)} failed extractions:\")\n",
    "temp_df[[\"data_group\", \"model\", \"scenario\", \"variable\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4a2f28-15e7-4994-b4b5-bd2b86db7604",
   "metadata": {},
   "source": [
    "How many files failed to download?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8e16d7a5-425a-468b-9223-f52f089f3c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 failed downloads:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_group</th>\n",
       "      <th>model</th>\n",
       "      <th>scenario</th>\n",
       "      <th>variable</th>\n",
       "      <th>hemisphere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>met_data</td>\n",
       "      <td>ec_earth3_veg_lr</td>\n",
       "      <td>historical</td>\n",
       "      <td>near_surface_air_temperature</td>\n",
       "      <td>west</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>met_data</td>\n",
       "      <td>ec_earth3_veg_lr</td>\n",
       "      <td>historical</td>\n",
       "      <td>near_surface_air_temperature</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>met_data</td>\n",
       "      <td>hadgem3_gc31_mm</td>\n",
       "      <td>ssp2_4_5</td>\n",
       "      <td>near_surface_air_temperature</td>\n",
       "      <td>west</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>met_data</td>\n",
       "      <td>hadgem3_gc31_mm</td>\n",
       "      <td>ssp2_4_5</td>\n",
       "      <td>near_surface_air_temperature</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>met_data</td>\n",
       "      <td>hadgem3_gc31_mm</td>\n",
       "      <td>ssp2_4_5</td>\n",
       "      <td>precipitation</td>\n",
       "      <td>west</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>water_balance_data</td>\n",
       "      <td>gfdl_esm4</td>\n",
       "      <td>historical</td>\n",
       "      <td>total_runoff</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>water_balance_data</td>\n",
       "      <td>gfdl_esm4</td>\n",
       "      <td>ssp2_4_5</td>\n",
       "      <td>surface_snow_amount</td>\n",
       "      <td>west</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>water_balance_data</td>\n",
       "      <td>gfdl_esm4</td>\n",
       "      <td>ssp2_4_5</td>\n",
       "      <td>surface_snow_amount</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>water_balance_data</td>\n",
       "      <td>gfdl_esm4</td>\n",
       "      <td>ssp5_8_5</td>\n",
       "      <td>surface_snow_amount</td>\n",
       "      <td>west</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>water_balance_data</td>\n",
       "      <td>gfdl_esm4</td>\n",
       "      <td>ssp5_8_5</td>\n",
       "      <td>surface_snow_amount</td>\n",
       "      <td>east</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             data_group             model    scenario  \\\n",
       "72             met_data  ec_earth3_veg_lr  historical   \n",
       "73             met_data  ec_earth3_veg_lr  historical   \n",
       "156            met_data   hadgem3_gc31_mm    ssp2_4_5   \n",
       "157            met_data   hadgem3_gc31_mm    ssp2_4_5   \n",
       "158            met_data   hadgem3_gc31_mm    ssp2_4_5   \n",
       "..                  ...               ...         ...   \n",
       "429  water_balance_data         gfdl_esm4  historical   \n",
       "436  water_balance_data         gfdl_esm4    ssp2_4_5   \n",
       "437  water_balance_data         gfdl_esm4    ssp2_4_5   \n",
       "446  water_balance_data         gfdl_esm4    ssp5_8_5   \n",
       "447  water_balance_data         gfdl_esm4    ssp5_8_5   \n",
       "\n",
       "                         variable hemisphere  \n",
       "72   near_surface_air_temperature       west  \n",
       "73   near_surface_air_temperature       east  \n",
       "156  near_surface_air_temperature       west  \n",
       "157  near_surface_air_temperature       east  \n",
       "158                 precipitation       west  \n",
       "..                            ...        ...  \n",
       "429                  total_runoff       east  \n",
       "436           surface_snow_amount       west  \n",
       "437           surface_snow_amount       east  \n",
       "446           surface_snow_amount       west  \n",
       "447           surface_snow_amount       east  \n",
       "\n",
       "[61 rows x 5 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = df[df[\"result\"] == \"fail\"]\n",
    "print(f\"{len(temp_df)} failed downloads:\")\n",
    "temp_df[[\"data_group\", \"model\", \"scenario\", \"variable\", \"hemisphere\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d6abb-0089-4bb8-b105-16f23dc8dca3",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "This section is just for showing some things to look out for when downloading data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bdde0d-1216-47a4-9491-ee6adad665a8",
   "metadata": {},
   "source": [
    "### Longitude restrictions for \"sea area percentage\"\n",
    "\n",
    "the longitude coordiantes for \"sea area percentage\" seem to be on a strictly positive axis (0, 360) and the positive bbox of the above (74, 174, 50, 240) causes errors, so we might just need to grab the whole grid for these ones.\n",
    "\n",
    "##### bbox with negative value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f997ce50-2233-4049-8036-98584d45406f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 13:29:11,313 INFO Welcome to the CDS\n",
      "2022-02-14 13:29:11,314 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2022-02-14 13:29:11,501 INFO Request is queued\n",
      "2022-02-14 13:29:12,681 INFO Request is running\n",
      "2022-02-14 13:29:16,795 INFO Request is failed\n",
      "2022-02-14 13:29:16,796 ERROR Message: an internal error occurred processing your request\n",
      "2022-02-14 13:29:16,796 ERROR Reason:  Process error: The requested longitude subset -120.0, 174.0 is not within the longitude bounds of this dataset and the data could not be converted to this longitude frame successfully. Please re-run your request with longitudes within the bounds of the dataset: 0.00, 359.99\n",
      "2022-02-14 13:29:16,797 ERROR   Traceback (most recent call last):\n",
      "2022-02-14 13:29:16,798 ERROR     File \"/usr/local/lib/python3.6/site-packages/rooki/results.py\", line 33, in url\n",
      "2022-02-14 13:29:16,799 ERROR       return self.response.get()[0]\n",
      "2022-02-14 13:29:16,800 ERROR     File \"/usr/local/lib/python3.6/site-packages/birdy/client/outputs.py\", line 30, in get\n",
      "2022-02-14 13:29:16,801 ERROR       raise ProcessFailed(\"Sorry, process failed.\")\n",
      "2022-02-14 13:29:16,801 ERROR   birdy.exceptions.ProcessFailed: Sorry, process failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('an internal error occurred processing your request. Process error: The requested longitude subset -120.0, 174.0 is not within the longitude bounds of this dataset and the data could not be converted to this longitude frame successfully. Please re-run your request with longitudes within the bounds of the dataset: 0.00, 359.99.',)\n"
     ]
    }
   ],
   "source": [
    "fp = scratch_dir.joinpath(\"test.zip\")\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "try:\n",
    "    c.retrieve(\n",
    "        'projections-cmip6',\n",
    "        {\n",
    "            'format': api_format,\n",
    "            'temporal_resolution': \"fixed\",\n",
    "            'experiment': \"historical\",\n",
    "            'level': 'single_levels',\n",
    "            'variable': \"sea_area_percentage\",\n",
    "            'model': \"noresm2_lm\",\n",
    "            \"area\": [74, 174, 50, -120]\n",
    "        },\n",
    "        fp\n",
    "    )\n",
    "except Exception as exc:\n",
    "    print(exc.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17f6b9-db0c-4cab-89c4-f174b7f92778",
   "metadata": {},
   "source": [
    "##### bbox with corresponding positive value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0507882f-c24d-49d4-bd64-f1173e1430f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 13:31:50,746 INFO Welcome to the CDS\n",
      "2022-02-14 13:31:50,747 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2022-02-14 13:31:50,935 INFO Request is queued\n",
      "2022-02-14 13:31:52,115 INFO Request is running\n",
      "2022-02-14 13:31:56,228 INFO Request is failed\n",
      "2022-02-14 13:31:56,229 ERROR Message: an internal error occurred processing your request\n",
      "2022-02-14 13:31:56,229 ERROR Reason:  execution failed\n",
      "2022-02-14 13:31:56,230 ERROR   Traceback (most recent call last):\n",
      "2022-02-14 13:31:56,231 ERROR     File \"/usr/local/lib/python3.6/site-packages/birdy/client/base.py\", line 347, in _execute\n",
      "2022-02-14 13:31:56,232 ERROR       pid, inputs=wps_inputs, output=wps_outputs, mode=mode\n",
      "2022-02-14 13:31:56,233 ERROR     File \"/usr/local/lib/python3.6/site-packages/owslib/wps.py\", line 359, in execute\n",
      "2022-02-14 13:31:56,234 ERROR       response = execution.submitRequest(request)\n",
      "2022-02-14 13:31:56,234 ERROR     File \"/usr/local/lib/python3.6/site-packages/owslib/wps.py\", line 912, in submitRequest\n",
      "2022-02-14 13:31:56,235 ERROR       self.url, request, method='Post', headers=self.headers)\n",
      "2022-02-14 13:31:56,236 ERROR     File \"/usr/local/lib/python3.6/site-packages/owslib/wps.py\", line 603, in readFromUrl\n",
      "2022-02-14 13:31:56,237 ERROR       headers=headers, verify=verify, cert=cert)\n",
      "2022-02-14 13:31:56,237 ERROR     File \"/usr/local/lib/python3.6/site-packages/owslib/wps.py\", line 515, in _readFromUrl\n",
      "2022-02-14 13:31:56,238 ERROR       headers=headers, verify=self.auth.verify, cert=self.auth.cert, timeout=timeout)\n",
      "2022-02-14 13:31:56,239 ERROR     File \"/usr/local/lib/python3.6/site-packages/owslib/util.py\", line 209, in openURL\n",
      "2022-02-14 13:31:56,240 ERROR       req.raise_for_status()\n",
      "2022-02-14 13:31:56,240 ERROR     File \"/usr/local/lib/python3.6/site-packages/requests/models.py\", line 941, in raise_for_status\n",
      "2022-02-14 13:31:56,241 ERROR       raise HTTPError(http_error_msg, response=self)\n",
      "2022-02-14 13:31:56,242 ERROR   requests.exceptions.HTTPError: 500 Server Error: INTERNAL SERVER ERROR for url: http://compute.mips.copernicus-climate.eu/wps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('an internal error occurred processing your request. execution failed.',)\n"
     ]
    }
   ],
   "source": [
    "fp = scratch_dir.joinpath(\"test.zip\")\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "try:\n",
    "    c.retrieve(\n",
    "        'projections-cmip6',\n",
    "        {\n",
    "            'format': api_format,\n",
    "            'temporal_resolution': \"fixed\",\n",
    "            'experiment': \"historical\",\n",
    "            'level': 'single_levels',\n",
    "            'variable': \"sea_area_percentage\",\n",
    "            'model': \"noresm2_lm\",\n",
    "            \"area\": [74, 174, 50, 240]\n",
    "        },\n",
    "        fp\n",
    "    )\n",
    "except Exception as exc:\n",
    "    print(exc.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b0fdd7-7690-4efc-8fda-09c722d2b260",
   "metadata": {},
   "source": [
    "### No support for multiple field values\n",
    "\n",
    "The CDS API does not support multiple values for a given field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f0a6da1-5bf6-49da-a650-e8fb624a1092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 13:36:23,676 INFO Welcome to the CDS\n",
      "2022-02-14 13:36:23,677 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2022-02-14 13:36:23,866 INFO Request is queued\n",
      "2022-02-14 13:36:25,049 INFO Request is running\n",
      "2022-02-14 13:36:29,161 INFO Request is failed\n",
      "2022-02-14 13:36:29,162 ERROR Message: an internal error occurred processing your request\n",
      "2022-02-14 13:36:29,163 ERROR Reason:  CMIP6 requests are limited to a single variable per request; please split your request into multiple requests.\n",
      "2022-02-14 13:36:29,164 ERROR   Traceback (most recent call last):\n",
      "2022-02-14 13:36:29,165 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/cdshandlers/services/handler.py\", line 55, in handle_request\n",
      "2022-02-14 13:36:29,166 ERROR       result = cached(context.method, proc, context, context.args, context.kwargs)\n",
      "2022-02-14 13:36:29,167 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/caching.py\", line 108, in cached\n",
      "2022-02-14 13:36:29,168 ERROR       result = proc(context, *context.args, **context.kwargs)\n",
      "2022-02-14 13:36:29,168 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 118, in __call__\n",
      "2022-02-14 13:36:29,169 ERROR       return p(*args, **kwargs)\n",
      "2022-02-14 13:36:29,170 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 59, in __call__\n",
      "2022-02-14 13:36:29,171 ERROR       return self.proc(context, *args, **kwargs)\n",
      "2022-02-14 13:36:29,171 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/__init__.py\", line 28, in execute\n",
      "2022-02-14 13:36:29,172 ERROR       _validate_request(request, list_params)  # Temporary measure to ensure single values for all kwargs\n",
      "2022-02-14 13:36:29,173 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/__init__.py\", line 55, in _validate_request\n",
      "2022-02-14 13:36:29,174 ERROR       f'CMIP6 requests are limited to a single {key} per request; '\n",
      "2022-02-14 13:36:29,174 ERROR   home.cds.cdsservices.services.esgf_wps.__init__.py.exceptions.InvalidRequestException: CMIP6 requests are limited to a single variable per request; please split your request into multiple requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('an internal error occurred processing your request. CMIP6 requests are limited to a single variable per request; please split your request into multiple requests..',)\n"
     ]
    }
   ],
   "source": [
    "# example with two variables supplied\n",
    "fp = scratch_dir.joinpath(\"test.zip\")\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "try:\n",
    "    c.retrieve(\n",
    "        'projections-cmip6',\n",
    "        {\n",
    "            'format': api_format,\n",
    "            'temporal_resolution': \"monthly\",\n",
    "            'experiment': \"historical\",\n",
    "            'level': 'single_levels',\n",
    "            'variable': [\"percipitation\", \"near_surface_air_temperature\"],\n",
    "            'model': \"cesm2\",\n",
    "            \"area\": [74, 174, 50, -120],\n",
    "            \"date\": \"1850-01-15/1851-12-31\",\n",
    "        },\n",
    "        fp\n",
    "    )\n",
    "except Exception as exc:\n",
    "    print(exc.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e714341-b95c-42e0-af28-8aa22212a20c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
