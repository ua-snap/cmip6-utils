{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5cc50df-ed13-409e-b2b8-0a6f59dc1c8b",
   "metadata": {},
   "source": [
    "# CMIP6 Deltas\n",
    "\n",
    "This notebook is for downloading monthly CMIP6 data and computing deltas. It is for an ad-hoc project to generate some useful CMIP6 summaries for Alaska while we await the infrastructure upgrades for accessing and working with larger amounts of data. The data downloaded here may be used in other efforts as well, such as statistical downscaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d4c0ad-3ca3-4dab-a3f4-fa3abb1127d9",
   "metadata": {},
   "source": [
    "# Download monthly CMIP6 data\n",
    "\n",
    "### Copernicus API\n",
    "\n",
    "This notebook will use the [Copernicus API](https://cds.climate.copernicus.eu/api-how-to#install-the-cds-api-key) to access data.\n",
    "\n",
    "The `cdsapi` python package will need to be installed, it is available via `pip` and on conda-forge: `conda install -c conda-forge cdsapi`. \n",
    "\n",
    "Credentials need to be placed in `$HOME/.cdsapirc` per the instructions at the link above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b79a349f-dc95-4ede-b4fb-4f4593e744a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - define all imports and paths\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cdsapi\n",
    "\n",
    "\n",
    "base_dir = Path(os.getenv(\"BASE_DIR\"))\n",
    "out_dir = Path(os.getenv(\"OUTPUT_DIR\"))\n",
    "scratch_dir = Path(os.getenv(\"SCRATCH_DIR\"))\n",
    "\n",
    "anc_dir = base_dir.joinpath(\"ancillary\")\n",
    "anc_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# tracking CSV filepath\n",
    "tracker_fp = anc_dir.joinpath(\"download_tracker.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203680e-1f4e-4e5f-b0a1-1820d9b0ce03",
   "metadata": {},
   "source": [
    "### Targets\n",
    "\n",
    "This section describes the various subsets of CMIP6 data we are interested in. There are three main groups:\n",
    "1. meterological data at monthly resolution (temp, precip, SLP)\n",
    "2. model data, for lack of a better term - data about the models\n",
    "3. water balance data at monthly resolution\n",
    "\n",
    "#### Meteorological data\n",
    "**Temporal resolution**: Monthly  \n",
    "**Experiment (4)**: Historical, SSP1-2.6, SSP2-4.5, SSP5-8.5  \n",
    "**Variable (3)**: Near-surface air temperature, Precipitation, Sea level pressure  \n",
    "**Model (12)**: ACCESS-CM2, CESM2, CNRM-CM6-1-HR, EC-Earth3-Veg-LR, GFDL-ESM4, HadGEM3-GC31-LL, HadGEM3-GC31-MM, KACE-1-0-G, MIROC6, MPI-ESM1-2-LR, MRI-ESM2-0, NorESM2-MM  \n",
    "\n",
    "\n",
    "#### Land surface data\n",
    "**Temporal resolution**: Fixed (no temporal resolution)  \n",
    "**Experiment (1)**: Historical  \n",
    "**Variable (3)**: Surface altitude, Percentage of the grid cell occupied by land including lakes, Sea area percentage  \n",
    "**Model (?)**: Subset of above, available  \n",
    "\n",
    "#### Water balance data\n",
    "**Temporal resolution**: Monthly  \n",
    "**Experiment (3)**: Historical, SSP2-4.5, SSP5-8.5  \n",
    "**Variable (5)**: Evaporation including sublimation and transpiration, Moisture in upper portion of soil column, snowfall flux, surface snow amount, total runoff  \n",
    "**Model (6)**: CESM2, EC-Earth3-Veg-LR, GFDL-ESM4, MIROC6, MRI-ESM2-0, NorESM2-MM  \n",
    "\n",
    "#### Fixed parameters\n",
    "For all of these groups, the following parameters will be constant:  \n",
    "**Level (1)**: single levels   \n",
    "**Geographical Area**: Sub-region extraction, North: 74, South 50, West 174, East -120   \n",
    "**Temporal subset**: Whole available temporal range  \n",
    "\n",
    "\n",
    "### Notes for downloading\n",
    "\n",
    "Here are some notes for downloading based on preliminary explorations:  \n",
    "\n",
    "* the CDS API does not support multiple values for a given field and so requests should be broken up by model, scenario (experiment), and variable\n",
    "* the longitude coordiantes for \"sea area percentage\" seem to be on a strictly positive axis (0, 360) and the positive bbox of the above (74, 174, 50, 240) causes errors, so we might just need to grab the whole grid for these ones.\n",
    "\n",
    "See the Appendix section for some examples of the above issues.\n",
    "\n",
    "### Define targets in a tracking table\n",
    "\n",
    "Make a table for tracking the progress of downloads with the following columns:\n",
    "\n",
    "* `data_group`: which of the above groups the download is for, either `\"met_vars\"`, `\"land_surface\"`, or `\"water_balance\"`\n",
    "* `model`\n",
    "* `scenario`\n",
    "* `variable`\n",
    "* `t_res`: temporal resolution, either `\"monthly\"` or `\"fixed\"`\n",
    "* `bbox`: spatial extent, in form (N, W, S, E), should be either `(74, 174, 50, -120)` or `None` (for sea area percentage only)\n",
    "* `result`: download result, either `\"pass\"`, `\"fail\"`, or `None`\n",
    "* `fail_reason`: fail message where applicable, or `None`\n",
    "* `zip_path`: path to where downloaded `.zip` data in `$SCRATCH_DIR` should be written\n",
    "* `base_path`: Path to where data should be unzipped and placed in `$BASE_DIR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8a5b68e9-5469-4b0e-b022-1a9c51639edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset tracker - set to True to reset tracking spreadsheet\n",
    "reset_tracker = True\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# make the tracking dataframe\n",
    "column_names = [\n",
    "    \"data_group\",\n",
    "    \"model\",\n",
    "    \"scenario\",\n",
    "    \"variable\",\n",
    "    \"t_res\",\n",
    "    \"bbox\",\n",
    "    \"result\",\n",
    "    \"fail_reason\",\n",
    "    \"zip_path\",\n",
    "    \"base_path\",\n",
    "]\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "if reset_tracker:\n",
    "    df.to_csv(tracker_fp, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f49e121-0a02-4ae6-85e3-c8ca7b0eb9f8",
   "metadata": {},
   "source": [
    "Start specifying the options for populating the table.\n",
    "\n",
    "##### Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7eb9c9fd-9016-485a-8d36-1065224bb6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a lookup dict for CDS API\n",
    "api_lu = {}\n",
    "\n",
    "# full names of models (for reference at this point)\n",
    "models = [\n",
    "    \"ACCESS-CM2\",\n",
    "    \"CESM2\",\n",
    "    \"CNRM-CM6-1-HR\",\n",
    "    \"EC-Earth3-Veg-LR\",\n",
    "    \"GFDL-ESM4\",\n",
    "    \"HadGEM3-GC31-LL\",\n",
    "    \"HadGEM3-GC31-MM\",\n",
    "    \"KACE-1-0-G\",\n",
    "    \"MIROC6\",\n",
    "    \"MPI-ESM1-2-LR\",\n",
    "    \"MRI-ESM2-0\",\n",
    "    \"NorESM2-MM\",\n",
    "]\n",
    "# api names for models are simply lower case and underscores instead of hyphens\n",
    "api_lu[\"models\"] = {model: model.lower().replace(\"-\", \"_\") for model in models}\n",
    "\n",
    "# subset of models for the water balanace data\n",
    "wb_models = [\n",
    "    \"CESM2\",\n",
    "    \"EC-Earth3-Veg-LR\",\n",
    "    \"GFDL-ESM4\",\n",
    "    \"MIROC6\",\n",
    "    \"MRI-ESM2-0\",\n",
    "    \"NorESM2-MM\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afde330-bc51-4f7b-b899-fb877d1d91a2",
   "metadata": {},
   "source": [
    "##### Scenarios (experiments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a17a5d31-60f9-4433-930e-c5711e895cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [\n",
    "    \"historical\",\n",
    "    \"SSP1-2.6\",\n",
    "    \"SSP2-4.5\",\n",
    "    \"SSP5-8.5\",\n",
    "]\n",
    "\n",
    "# water balance scenarios\n",
    "wb_scenarios = [\n",
    "    \"historical\",\n",
    "    \"SSP2-4.5\",\n",
    "    \"SSP5-8.5\",\n",
    "]\n",
    "\n",
    "# lookups for API\n",
    "api_lu[\"scenarios\"] = {\n",
    "    \"historical\": \"historical\",\n",
    "    \"SSP1-2.6\": \"ssp1_2_6\",\n",
    "    \"SSP2-4.5\": \"ssp2_4_5\",\n",
    "    \"SSP5-8.5\": \"ssp5_8_5\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252e753-89f7-4c9b-a19e-4ca9ff6bc4ed",
   "metadata": {},
   "source": [
    "##### Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d44330cf-993d-4923-a0fd-1f4ce90717d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_varnames = [\"tas\", \"pr\", \"slp\"]\n",
    "land_varnames = [\"orog\", \"sftlf\", \"sftof\", \"evspsbl\", \"mrsos\"]\n",
    "wb_varnames = [\"prsn\", \"snw\", \"mrro\"]\n",
    "\n",
    "# variable names\n",
    "api_lu[\"varnames\"] = {\n",
    "    \"tas\": \"near_surface_air_temperature\",\n",
    "    \"pr\": \"precipitation\",\n",
    "    \"slp\": \"sea_level_pressure\",\n",
    "    \"orog\": \"surface_altitude\",\n",
    "    \"sftlf\": \"percentage_of_the_grid_cell_occupied_by_land_including_lakes\",\n",
    "    \"sftof\": \"sea_area_percentage\",\n",
    "    \"evspsbl\": \"evaporation_including_sublimation_and_transpiration\",\n",
    "    \"mrsos\": \"moisture_in_upper_portion_of_soil_column\",\n",
    "    \"prsn\": \"snowfall_flux\",\n",
    "    \"snw\": \"surface_snow_amount\",\n",
    "    \"mrro\": \"total_runoff\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b82adb6-1310-4220-9db6-9baa56e8a2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d2c8008-9e15-47a8-8280-c672c091aee4",
   "metadata": {},
   "source": [
    "##### Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cde844dd-a445-4738-8c78-706fd4497f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these will stay constant over all model combinations\n",
    "level = \"single_levels\"\n",
    "bbox = [74, 174, 50, -120] #N W S E\n",
    "api_format = \"zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fad6d8-73bc-4b7e-b030-5200cd4f5ddb",
   "metadata": {},
   "source": [
    "Start populating the table:\n",
    "\n",
    "##### Met vars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "79fdd6de-847d-46fe-9979-327653ced949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the df\n",
    "df = pd.read_csv(tracker_fp)\n",
    "\n",
    "monthly_zip_fn = \"{}_monthly_mean_{}_{}.zip\"\n",
    "for model in models:\n",
    "    for scenario in scenarios:\n",
    "        for varname in met_varnames:\n",
    "            row_df = {\n",
    "                \"data_group\": \"met_vars\",\n",
    "                \"model\": api_lu[\"models\"][model],\n",
    "                \"scenario\": api_lu[\"scenarios\"][scenario],\n",
    "                \"variable\": api_lu[\"varnames\"][varname],\n",
    "                \"t_res\": \"monthly\",\n",
    "                \"bbox\": bbox,\n",
    "                \"result\": None,\n",
    "                \"fail_reason\": None\n",
    "            }\n",
    "            # make zip download path\n",
    "            row_df[\"zip_path\"] = scratch_dir.joinpath(\n",
    "                monthly_zip_fn.format(varname, model, scenario)\n",
    "            )\n",
    "            row_df[\"base_path\"] = None\n",
    "            df = df.append(row_df, ignore_index=True)\n",
    "\n",
    "# write the df           \n",
    "df.to_csv(tracker_fp, index=False)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c3c964-4641-484b-a0f7-84b3144501da",
   "metadata": {},
   "source": [
    "##### Land surface vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ef26ff19-f4a7-4f8b-be74-d0fd3e526eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the df\n",
    "df = pd.read_csv(tracker_fp)\n",
    "\n",
    "land_zip_fn = \"{}_fx_historical.zip\"\n",
    "for model in models:\n",
    "    for varname in land_varnames:\n",
    "        row_df = {\n",
    "            \"data_group\": \"land_surface\",\n",
    "            \"model\": api_lu[\"models\"][model],\n",
    "            \"scenario\": \"historical\",\n",
    "            \"variable\": api_lu[\"varnames\"][varname],\n",
    "            \"t_res\": \"fixed\",\n",
    "            \"bbox\": bbox,\n",
    "            \"result\": None,\n",
    "            \"fail_reason\": None\n",
    "        }\n",
    "        # set the bbox to None if varname is sftof (sea area percentage)\n",
    "        if varname == \"sftof\":\n",
    "            row_df[\"bbox\"] = None\n",
    "        # make zip download path\n",
    "        row_df[\"zip_path\"] = scratch_dir.joinpath(\n",
    "            land_zip_fn.format(varname)\n",
    "        )\n",
    "        row_df[\"base_path\"] = None\n",
    "        df = df.append(row_df, ignore_index=True)\n",
    "\n",
    "# write the df           \n",
    "df.to_csv(tracker_fp, index=False)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c68765-89f8-4eef-9483-4cd41a661d9d",
   "metadata": {},
   "source": [
    "##### Water balance vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9a482b55-8022-40c5-8946-f97a753ea6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the df\n",
    "df = pd.read_csv(tracker_fp)\n",
    "\n",
    "monthly_zip_fn = \"{}_monthly_mean_{}_{}.zip\"\n",
    "for model in wb_models:\n",
    "    for scenario in wb_scenarios:\n",
    "        for varname in wb_varnames:\n",
    "            row_df = {\n",
    "                \"data_group\": \"water_balance\",\n",
    "                \"model\": api_lu[\"models\"][model],\n",
    "                \"scenario\": api_lu[\"scenarios\"][scenario],\n",
    "                \"variable\": api_lu[\"varnames\"][varname],\n",
    "                \"t_res\": \"monthly\",\n",
    "                \"bbox\": bbox,\n",
    "                \"result\": None,\n",
    "                \"fail_reason\": None\n",
    "            }\n",
    "            # make zip download path\n",
    "            row_df[\"zip_path\"] = scratch_dir.joinpath(\n",
    "                monthly_zip_fn.format(varname, model, scenario)\n",
    "            )\n",
    "            row_df[\"base_path\"] = None\n",
    "            df = df.append(row_df, ignore_index=True)\n",
    "\n",
    "# write the df           \n",
    "df.to_csv(tracker_fp, index=False)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca10ba4-9b9b-4de4-b36e-2641b8870e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a idempotent function for updating the tracking \n",
    "# dataframe based on presence of files in $SCRATCH_DIR and $BASE_DIR\n",
    "\n",
    "def update_tracker(base_dir, scratch_dir):\n",
    "    \"\"\"Update the tracking table based on presence of files\n",
    "    \n",
    "    Args:\n",
    "        base_dir (pathlib.PosixPath): path to base directory that should have an\n",
    "            ancillary/ folder with the tracking spreadsheet in it\n",
    "        scratch_dir(pathlib.PosixPath): path to the scratch directory, where API requests\n",
    "            are downloaded to\n",
    "            \n",
    "    Returns:\n",
    "        Nothing, prints the number of records updated\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d6abb-0089-4bb8-b105-16f23dc8dca3",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "This section is just for showing some things to look out for when downloading data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bdde0d-1216-47a4-9491-ee6adad665a8",
   "metadata": {},
   "source": [
    "### Longitude restrictions for \"sea area percentage\"\n",
    "\n",
    "the longitude coordiantes for \"sea area percentage\" seem to be on a strictly positive axis (0, 360) and the positive bbox of the above (74, 174, 50, 240) causes errors, so we might just need to grab the whole grid for these ones.\n",
    "\n",
    "##### bbox with negative value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f997ce50-2233-4049-8036-98584d45406f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 13:29:11,313 INFO Welcome to the CDS\n",
      "2022-02-14 13:29:11,314 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2022-02-14 13:29:11,501 INFO Request is queued\n",
      "2022-02-14 13:29:12,681 INFO Request is running\n",
      "2022-02-14 13:29:16,795 INFO Request is failed\n",
      "2022-02-14 13:29:16,796 ERROR Message: an internal error occurred processing your request\n",
      "2022-02-14 13:29:16,796 ERROR Reason:  Process error: The requested longitude subset -120.0, 174.0 is not within the longitude bounds of this dataset and the data could not be converted to this longitude frame successfully. Please re-run your request with longitudes within the bounds of the dataset: 0.00, 359.99\n",
      "2022-02-14 13:29:16,797 ERROR   Traceback (most recent call last):\n",
      "2022-02-14 13:29:16,798 ERROR     File \"/usr/local/lib/python3.6/site-packages/rooki/results.py\", line 33, in url\n",
      "2022-02-14 13:29:16,799 ERROR       return self.response.get()[0]\n",
      "2022-02-14 13:29:16,800 ERROR     File \"/usr/local/lib/python3.6/site-packages/birdy/client/outputs.py\", line 30, in get\n",
      "2022-02-14 13:29:16,801 ERROR       raise ProcessFailed(\"Sorry, process failed.\")\n",
      "2022-02-14 13:29:16,801 ERROR   birdy.exceptions.ProcessFailed: Sorry, process failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('an internal error occurred processing your request. Process error: The requested longitude subset -120.0, 174.0 is not within the longitude bounds of this dataset and the data could not be converted to this longitude frame successfully. Please re-run your request with longitudes within the bounds of the dataset: 0.00, 359.99.',)\n"
     ]
    }
   ],
   "source": [
    "fp = scratch_dir.joinpath(\"test.zip\")\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "try:\n",
    "    c.retrieve(\n",
    "        'projections-cmip6',\n",
    "        {\n",
    "            'format': api_format,\n",
    "            'temporal_resolution': \"fixed\",\n",
    "            'experiment': \"historical\",\n",
    "            'level': 'single_levels',\n",
    "            'variable': \"sea_area_percentage\",\n",
    "            'model': \"noresm2_lm\",\n",
    "            \"area\": [74, 174, 50, -120]\n",
    "        },\n",
    "        fp\n",
    "    )\n",
    "except Exception as exc:\n",
    "    print(exc.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17f6b9-db0c-4cab-89c4-f174b7f92778",
   "metadata": {},
   "source": [
    "##### bbox with corresponding positive value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0507882f-c24d-49d4-bd64-f1173e1430f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 13:31:50,746 INFO Welcome to the CDS\n",
      "2022-02-14 13:31:50,747 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2022-02-14 13:31:50,935 INFO Request is queued\n",
      "2022-02-14 13:31:52,115 INFO Request is running\n",
      "2022-02-14 13:31:56,228 INFO Request is failed\n",
      "2022-02-14 13:31:56,229 ERROR Message: an internal error occurred processing your request\n",
      "2022-02-14 13:31:56,229 ERROR Reason:  execution failed\n",
      "2022-02-14 13:31:56,230 ERROR   Traceback (most recent call last):\n",
      "2022-02-14 13:31:56,231 ERROR     File \"/usr/local/lib/python3.6/site-packages/birdy/client/base.py\", line 347, in _execute\n",
      "2022-02-14 13:31:56,232 ERROR       pid, inputs=wps_inputs, output=wps_outputs, mode=mode\n",
      "2022-02-14 13:31:56,233 ERROR     File \"/usr/local/lib/python3.6/site-packages/owslib/wps.py\", line 359, in execute\n",
      "2022-02-14 13:31:56,234 ERROR       response = execution.submitRequest(request)\n",
      "2022-02-14 13:31:56,234 ERROR     File \"/usr/local/lib/python3.6/site-packages/owslib/wps.py\", line 912, in submitRequest\n",
      "2022-02-14 13:31:56,235 ERROR       self.url, request, method='Post', headers=self.headers)\n",
      "2022-02-14 13:31:56,236 ERROR     File \"/usr/local/lib/python3.6/site-packages/owslib/wps.py\", line 603, in readFromUrl\n",
      "2022-02-14 13:31:56,237 ERROR       headers=headers, verify=verify, cert=cert)\n",
      "2022-02-14 13:31:56,237 ERROR     File \"/usr/local/lib/python3.6/site-packages/owslib/wps.py\", line 515, in _readFromUrl\n",
      "2022-02-14 13:31:56,238 ERROR       headers=headers, verify=self.auth.verify, cert=self.auth.cert, timeout=timeout)\n",
      "2022-02-14 13:31:56,239 ERROR     File \"/usr/local/lib/python3.6/site-packages/owslib/util.py\", line 209, in openURL\n",
      "2022-02-14 13:31:56,240 ERROR       req.raise_for_status()\n",
      "2022-02-14 13:31:56,240 ERROR     File \"/usr/local/lib/python3.6/site-packages/requests/models.py\", line 941, in raise_for_status\n",
      "2022-02-14 13:31:56,241 ERROR       raise HTTPError(http_error_msg, response=self)\n",
      "2022-02-14 13:31:56,242 ERROR   requests.exceptions.HTTPError: 500 Server Error: INTERNAL SERVER ERROR for url: http://compute.mips.copernicus-climate.eu/wps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('an internal error occurred processing your request. execution failed.',)\n"
     ]
    }
   ],
   "source": [
    "fp = scratch_dir.joinpath(\"test.zip\")\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "try:\n",
    "    c.retrieve(\n",
    "        'projections-cmip6',\n",
    "        {\n",
    "            'format': api_format,\n",
    "            'temporal_resolution': \"fixed\",\n",
    "            'experiment': \"historical\",\n",
    "            'level': 'single_levels',\n",
    "            'variable': \"sea_area_percentage\",\n",
    "            'model': \"noresm2_lm\",\n",
    "            \"area\": [74, 174, 50, 240]\n",
    "        },\n",
    "        fp\n",
    "    )\n",
    "except Exception as exc:\n",
    "    print(exc.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b0fdd7-7690-4efc-8fda-09c722d2b260",
   "metadata": {},
   "source": [
    "### No support for multiple field values\n",
    "\n",
    "The CDS API does not support multiple values for a given field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f0a6da1-5bf6-49da-a650-e8fb624a1092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 13:36:23,676 INFO Welcome to the CDS\n",
      "2022-02-14 13:36:23,677 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2022-02-14 13:36:23,866 INFO Request is queued\n",
      "2022-02-14 13:36:25,049 INFO Request is running\n",
      "2022-02-14 13:36:29,161 INFO Request is failed\n",
      "2022-02-14 13:36:29,162 ERROR Message: an internal error occurred processing your request\n",
      "2022-02-14 13:36:29,163 ERROR Reason:  CMIP6 requests are limited to a single variable per request; please split your request into multiple requests.\n",
      "2022-02-14 13:36:29,164 ERROR   Traceback (most recent call last):\n",
      "2022-02-14 13:36:29,165 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/cdshandlers/services/handler.py\", line 55, in handle_request\n",
      "2022-02-14 13:36:29,166 ERROR       result = cached(context.method, proc, context, context.args, context.kwargs)\n",
      "2022-02-14 13:36:29,167 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/caching.py\", line 108, in cached\n",
      "2022-02-14 13:36:29,168 ERROR       result = proc(context, *context.args, **context.kwargs)\n",
      "2022-02-14 13:36:29,168 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 118, in __call__\n",
      "2022-02-14 13:36:29,169 ERROR       return p(*args, **kwargs)\n",
      "2022-02-14 13:36:29,170 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 59, in __call__\n",
      "2022-02-14 13:36:29,171 ERROR       return self.proc(context, *args, **kwargs)\n",
      "2022-02-14 13:36:29,171 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/__init__.py\", line 28, in execute\n",
      "2022-02-14 13:36:29,172 ERROR       _validate_request(request, list_params)  # Temporary measure to ensure single values for all kwargs\n",
      "2022-02-14 13:36:29,173 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/__init__.py\", line 55, in _validate_request\n",
      "2022-02-14 13:36:29,174 ERROR       f'CMIP6 requests are limited to a single {key} per request; '\n",
      "2022-02-14 13:36:29,174 ERROR   home.cds.cdsservices.services.esgf_wps.__init__.py.exceptions.InvalidRequestException: CMIP6 requests are limited to a single variable per request; please split your request into multiple requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('an internal error occurred processing your request. CMIP6 requests are limited to a single variable per request; please split your request into multiple requests..',)\n"
     ]
    }
   ],
   "source": [
    "# example with two variables supplied\n",
    "fp = scratch_dir.joinpath(\"test.zip\")\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "try:\n",
    "    c.retrieve(\n",
    "        'projections-cmip6',\n",
    "        {\n",
    "            'format': api_format,\n",
    "            'temporal_resolution': \"monthly\",\n",
    "            'experiment': \"historical\",\n",
    "            'level': 'single_levels',\n",
    "            'variable': [\"percipitation\", \"near_surface_air_temperature\"],\n",
    "            'model': \"cesm2\",\n",
    "            \"area\": [74, 174, 50, -120],\n",
    "            \"date\": \"1850-01-15/1851-12-31\",\n",
    "        },\n",
    "        fp\n",
    "    )\n",
    "except Exception as exc:\n",
    "    print(exc.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e714341-b95c-42e0-af28-8aa22212a20c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
