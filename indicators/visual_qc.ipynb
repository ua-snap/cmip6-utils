{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual QC notebook\n",
    "\n",
    "This notebook is designed to be used in a visual QC check of computed indicators. Indicator files are counted, and 20% of the files are randomly selected for QC. Using only the output file names, we will:\n",
    "- locate the original source data used to compute the indicators\n",
    "- recompute the indicators\n",
    "- compare the two datasets numerically (they should equal each other), visually (they should look the same when plotted), and contextually (known regions or features should make sense with regard to shape/size, location of coastlines, reasonable indicator values, etc).\n",
    "\n",
    "#### How to use with `prefect` via `papermill`: \n",
    "\n",
    "This notebook should be run as the final step of the `prefect` indicator flow. The output will be saved as a new notebook in the QC directory created during the flow. To accomplish this, create a task in the `prefect` flow that will execute this notebook from the command line using `papermill`, e.g.:\n",
    "\n",
    "```papermill path/to/repo/indicators/visual_qc.ipynb path/to/qc/output/output.ipynb -r working_directory \"/path/to/working/dir\" -r input_directory \"/path/to/input/dir\"```\n",
    "\n",
    "\n",
    " The first argument is this notebook's location, which can be constructed using the `{working_directory}` parameter of the flow run (ie, the notebook's location within the downloaded repo directory). The second argument is the desired notebook output location, which can also be constructed using the `{working_directory}` parameter of the flow run. The remaining arguments are raw strings (denoted by `-r`) of the working and input directories used in the flow run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Papermill parameter cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this cell is tagged \"parameters\" and contains default parameter values for this notebook\n",
    "# parameters injected by papermill from the command line will be written into a new cell directly beneath this one, and will override the values in this cell\n",
    "\n",
    "working_directory = \"/import/beegfs/CMIP6/snapdata/\"\n",
    "input_directory = \"/import/beegfs/CMIP6/arctic-cmip6/regrid/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from indicators import *\n",
    "from luts import idx_varid_lu, varid_freqs\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "Define data sources and parameters for QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dirs to Path objects\n",
    "input_dir = Path(input_directory)\n",
    "output_dir = Path(working_directory).joinpath(\"output/\")\n",
    "\n",
    "#list all netCDF files in the output directory\n",
    "output_files = [f for f in output_dir.glob(\"**/*.nc\")]\n",
    "\n",
    "#randomly pick 20% of the output files for visual QC\n",
    "qc_files = random.sample(output_files, round(len(output_files) * .2))\n",
    "\n",
    "#lat/lon slices and titles for these regions\n",
    "lat_slices = [slice(45, 65), slice(55, 75), slice(60, 80)]\n",
    "lon_slices = [slice(90, 120), slice(180, 210), slice(310, 340)]\n",
    "region_titles = [\"Lake Baikal\", \"Seward Peninsula\", \"Greenland\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that will deconstruct the file path of a computed indicator, and use its parts to locate the source files used to compute that indicator. The indicator is recomputed, all years are merged, and output is an `xarray.Dataset` that should be an exact match of the original indicator file. **Note that this will grab all regridded source files for each variable!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_inputs_and_recompute_indicator(fp, input_dir):\n",
    "    source_files={}\n",
    "    indicator, model, scenario = fp.parts[-1].split(\"_\")[0], fp.parts[-1].split(\"_\")[1], fp.parts[-1].split(\"_\")[2]\n",
    "    vars = idx_varid_lu[indicator]\n",
    "    for var in vars:\n",
    "        frequency = varid_freqs[var][0]\n",
    "        source_files[var]=[f for f in input_dir.joinpath(model, scenario, frequency, var).glob(\"**/*.nc\")]\n",
    "        \n",
    "    coord_labels = dict(scenario=scenario,model=model)\n",
    "    ds = xr.merge(run_compute_indicators(source_files, [indicator], coord_labels))\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to test if two `xarray.Dataset`s are equal, and return a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_they_equal(fp, ds1, ds2):\n",
    "    if ds1.equals(ds2):\n",
    "        print(f\"PASS: Recomputed indicator data from {fp} is identical to original.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"FAIL: Recomputed indicator data from {fp} does not match to original.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that will slice the recomputed indicator dataset by lat/lon, and plot a random year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_and_plot(fp, ds1, ds2):\n",
    "    var = [i for i in ds1.data_vars][0]\n",
    "    y = random.sample(ds1.year.values.tolist(), 1)[0]\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
    "\n",
    "    rpt_ds = [ele for ele in [ds1, ds2] for i in range(3)]\n",
    "    rpt_subtitles = [ele for ele in [\"Original\", \"Recomputed\"] for i in range(3)]\n",
    "    \n",
    "    for ax, lat_slice, lon_slice, ds, title, subtitle in zip(axes.T.flat, lat_slices*2, lon_slices*2, rpt_ds, region_titles*2, rpt_subtitles):\n",
    "        ds[var].sel(year=y, lat=lat_slice, lon=lon_slice).plot(ax=ax, vmin=0, add_labels=False)\n",
    "        ax.set_title(f\"{title}: {subtitle}\", fontsize=14)\n",
    "    \n",
    "    fp_str = str(fp)\n",
    "    fig.suptitle(f\"Plotting file: {fp_str} \\n Year: {y} \\n Indicator: {var} \\n Attributes: {ds1[var].attrs}\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the recomputation & plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS: Recomputed indicator data from /import/beegfs/CMIP6/snapdata/output/CESM2/ssp126/rx1day/rx1day_CESM2_ssp126_indicator.nc is identical to original.\n"
     ]
    }
   ],
   "source": [
    "original_datasets = []\n",
    "recomputed_datasets = []\n",
    "\n",
    "for f in qc_files[0:3]:\n",
    "    recomputed_ds = find_inputs_and_recompute_indicator(f, input_dir)\n",
    "    recomputed_datasets.append(recomputed_ds)\n",
    "    original_ds = xr.open_dataset(f)\n",
    "    original_datasets.append(original_ds)\n",
    "    #print the equality statements together for easy viewing\n",
    "    are_they_equal(f, original_ds, recomputed_ds)\n",
    "\n",
    "for f, o, r in zip(qc_files[0:3], original_datasets, recomputed_datasets):\n",
    "    slice_and_plot(f, o, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmip6-utils2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
