{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "import cftime\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xclim.indices as xci\n",
    "from xclim.core.calendar import percentile_doy\n",
    "from xclim.core.units import convert_units_to, to_agg_units\n",
    "from xclim.indices.generic import threshold_count\n",
    "from xclim.indicators import icclim\n",
    "from config import *\n",
    "from luts import varid_idx_lu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rx1day(pr):\n",
    "    \"\"\"'Max 1-day precip' - the max daily precip value recorded for a year.\n",
    "\n",
    "    Args:\n",
    "        pr (xarray.DataArray): daily total precip values\n",
    "\n",
    "    Returns:\n",
    "        Max 1-day precip for each year\n",
    "    \"\"\"\n",
    "    out = xci.max_n_day_precipitation_amount(pr, freq=\"YS\")\n",
    "    out.attrs[\"units\"] = \"mm\"\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def rx5day(pr):\n",
    "    \"\"\"'Max 5-day precip' - the max 5-day precip value recorded for a year.\n",
    "\n",
    "    Args:\n",
    "        pr (xarray.DataArray): daily total precip values\n",
    "\n",
    "    Returns:\n",
    "        Max 5-day precip for each year\n",
    "    \"\"\"\n",
    "    out = xci.max_n_day_precipitation_amount(pr, 5, freq=\"YS\")\n",
    "    out.attrs[\"units\"] = \"mm\"\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def r10mm(pr):\n",
    "    \"\"\"'Heavy precip days' - number of days in a year with over 10mm of precip\n",
    "\n",
    "    Args:\n",
    "        pr (xarray.DataArray): daily total precip values\n",
    "\n",
    "    Returns:\n",
    "        Number of heavy precip days for each year\n",
    "    \"\"\"\n",
    "    return icclim.R10mm(pr)\n",
    "\n",
    "\n",
    "def cwd(pr):\n",
    "    \"\"\"'Consecutive wet days' - number of the most consecutive days with precip > 1 mm\n",
    "\n",
    "    Args:\n",
    "        pr (xarray.DataArray): daily total precip values\n",
    "\n",
    "    Returns:\n",
    "        Max number of consecutive wet days for each year\n",
    "    \"\"\"\n",
    "    return xci.maximum_consecutive_wet_days(pr, thresh=f\"1 mm/day\", freq=\"YS\")\n",
    "\n",
    "\n",
    "def cdd(pr):\n",
    "    \"\"\"'Consecutive dry days' - number of the most consecutive days with precip < 1 mm\n",
    "\n",
    "    Args:\n",
    "        pr (xarray.DataArray): daily total precip values\n",
    "\n",
    "    Returns:\n",
    "        Max number of consecutive dry days for each year\n",
    "    \"\"\"\n",
    "    return xci.maximum_consecutive_dry_days(pr, thresh=f\"1 mm/day\", freq=\"YS\")\n",
    "\n",
    "\n",
    "def convert_times_to_years(time_da):\n",
    "    \"\"\"Convert the time values in a time axis (DataArray) to integer year values. Handles cftime types and numpy.datetime64.\"\"\"\n",
    "    if time_da.values.dtype == np.dtype(\"<M8[ns]\"):\n",
    "        # just a double check that we have nanosecond precision since we will divide by 1e9 to get seconds\n",
    "        assert len(str(time_da.values[0])) == 29\n",
    "        cftimes = [\n",
    "            cftime.num2date(t / 1e9, \"seconds since 1970-01-01\")\n",
    "            for t in time_da.values.astype(int)\n",
    "        ]\n",
    "    elif isinstance(\n",
    "        time_da.values[0],\n",
    "        cftime._cftime.Datetime360Day,\n",
    "    ) or isinstance(\n",
    "        time_da.values[0],\n",
    "        cftime._cftime.DatetimeNoLeap,\n",
    "    ):\n",
    "        cftimes = time_da.values\n",
    "\n",
    "    years = [t.year for t in cftimes]\n",
    "\n",
    "    return years\n",
    "\n",
    "\n",
    "def compute_indicator(da, idx, coord_labels, kwargs={}):\n",
    "    \"\"\"Summarize a DataArray according to a specified index / aggregation function\n",
    "\n",
    "    Args:\n",
    "        da (xarray.DataArray): the DataArray object containing the base variable data to b summarized according to aggr\n",
    "        idx (str): String corresponding to the name of the indicator to compute (assumes value is equal to the name of the corresponding global function)\n",
    "        coord_labels (dict): dict with model and scenario as keys for labeling resulting xarray dataset coordinates.\n",
    "        kwargs (dict): additional arguments for the index function being called\n",
    "\n",
    "    Returns:\n",
    "        A new data array with dimensions year, latitude, longitude, in that order containing the summarized information\n",
    "    \"\"\"\n",
    "    new_da = (\n",
    "        globals()[idx](da, **kwargs)\n",
    "        # .transpose(\"time\", \"lat\", \"lon\")\n",
    "        # .reset_coords([\"longitude\", \"latitude\", \"height\"], drop=True)\n",
    "    )\n",
    "    new_da.name = idx\n",
    "    # get the nodata mask from first time slice\n",
    "    nodata = np.broadcast_to(np.isnan(da.sel(time=da[\"time\"].values[0])), new_da.shape)\n",
    "    # remask, because xclim switches nans to 0\n",
    "    # xclim is inconsistent about the types returned.\n",
    "    if new_da.dtype in [np.int32, np.int64]:\n",
    "        new_da.values[nodata] = -9999\n",
    "    else:\n",
    "        new_da.values[nodata] = np.nan\n",
    "\n",
    "    new_dims = list(coord_labels.keys())\n",
    "    new_da = new_da.assign_coords(coord_labels).expand_dims(new_dims)\n",
    "    # convert the time dimension to integer years instead of CF time objects\n",
    "    years = convert_times_to_years(new_da.time)\n",
    "    new_da = new_da.rename({\"time\": \"year\"}).assign_coords({\"year\": years})\n",
    "\n",
    "    return new_da\n",
    "\n",
    "\n",
    "def run_compute_indicators(fps, idx_list, coord_labels, kwargs={}):\n",
    "    \"\"\"Open connections to data files for a particular model variable, scenario, and model and compute all requested indicators.\n",
    "\n",
    "    Args:\n",
    "        fps (path-like): paths to the files for the variable required for creating the indicators variables\n",
    "        idx_list (list): indices to derive using data in provided filepath\n",
    "        # var_id (str): model variable being used for indices\n",
    "        coord_labels (dict): dict with model and scenario as keys for labeling resulting xarray dataset coordinates.\n",
    "\n",
    "    Returns:\n",
    "        summary_das (tuple): tuple of the form (da, index, scenario, model), where da is a DataArray with dimensions of year (summary year), latitude (lat) and longitude (lon)\n",
    "    \"\"\"\n",
    "    with xr.open_mfdataset(fps) as ds:\n",
    "        var_id = ds.attrs[\"variable_id\"]\n",
    "        out = []\n",
    "        for idx in idx_list:\n",
    "            if idx in [\"wsdi\", \"csdi\"]:\n",
    "                # for these special indices we need to derive percentiles\n",
    "                #  from the historical data\n",
    "                with xr.open_mfdataset(hist_fps) as hist_ds:\n",
    "                    kwargs = {\"hist_da\": hist_ds[var_id]}\n",
    "                    out.append(\n",
    "                        compute_indicator(\n",
    "                            da=ds[var_id],\n",
    "                            idx=idx,\n",
    "                            coord_labels=coord_labels,\n",
    "                            kwargs=kwargs,\n",
    "                        )\n",
    "                    )\n",
    "                pass\n",
    "            else:\n",
    "                out.append(\n",
    "                    compute_indicator(\n",
    "                        da=ds[var_id], idx=idx, coord_labels=coord_labels, kwargs=kwargs\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable_id = \"pr\"\n",
    "# scenario = \"historical\"\n",
    "# model = \"CESM2\"\n",
    "regrid_dir = Path(\"/center1/CMIP6/kmredilla/cmip6_regridding/regrid/\")\n",
    "\n",
    "# models will just be all models in regrid dir\n",
    "models = [d.name for d in regrid_dir.glob(\"*\")]\n",
    "scenarios = [\"historical\", \"ssp245\", \"ssp585\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_base_kwargs(scenarios, models, var_id, idx_list, input_dir):\n",
    "    kwargs_list = []\n",
    "    for scenario in scenarios:\n",
    "        for model in models:\n",
    "            fps = list(\n",
    "                input_dir.joinpath(f\"{model}/{scenario}/day/{var_id}\").glob(\"*.nc\")\n",
    "            )\n",
    "\n",
    "            # not all combinations of model, scenario, and model variable actually exist\n",
    "            if len(fps) > 0:\n",
    "                coord_labels = dict(\n",
    "                    scenario=scenario,\n",
    "                    model=model,\n",
    "                )\n",
    "                kwargs_list.append(\n",
    "                    dict(\n",
    "                        fps=fps,\n",
    "                        idx_list=idx_list,\n",
    "                        coord_labels=coord_labels,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    return kwargs_list\n",
    "\n",
    "\n",
    "def add_xsdi_kwargs(kwargs_list, input_dir):\n",
    "    \"\"\"Add kwargs for cold and warm spell duration indices. This should just be the historical data filepaths for computing percentiles.\"\"\"\n",
    "    for kwargs in kwargs_list:\n",
    "        # make sure at least one of the indicators is an \"<warm/cold> spell duration index\"\n",
    "        assert np.any([idx in [\"wsdi\", \"csdi\"] for idx in kwargs[\"idx_list\"]])\n",
    "\n",
    "        coord_labels = [\"model\"]\n",
    "        fps = list(\n",
    "            input_dir.joinpath(\n",
    "                f\"{coord_labels['model']}/{coord_labels['scenario']}/day/{kwargs['var_id']}\"\n",
    "            ).glob(\"*.nc\")\n",
    "        )\n",
    "\n",
    "        kwargs[\"hist_fps\"] = fps\n",
    "\n",
    "    return kwargs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_id = \"pr\"\n",
    "idx_list = varid_idx_lu[var_id]\n",
    "kwargs_list = generate_base_kwargs(scenarios, models, var_id, idx_list, regrid_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", r\"All-NaN (slice|axis) encountered\")\n",
    "    for kwarg in tqdm.tqdm(kwargs_list):\n",
    "        out.append(xr.merge(run_compute_indicators(**kwarg)).compute())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators_ds = xr.merge(out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmip6-utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
