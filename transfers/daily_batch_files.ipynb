{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e072f06-8aa6-4654-9e46-19347f5d8911",
   "metadata": {},
   "source": [
    "# Create files for `globus transfer --batch` on daily data\n",
    "\n",
    "This notebook is used to generate the `batch_files/batch*day*.txt` files that contain the files to transfer to the Arctic Climate Data Node. Currently, this is done from the LLNL node only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1794241-a662-4222-8441-a0d7e41b066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import luts\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def8ac03-117f-456e-9b9e-00cc0ef0fbf9",
   "metadata": {},
   "source": [
    "Read in the main table of desired filenames at the daily temporal resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e2db0ed-d4ab-4064-9bc5-b7a7258c4674",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"llnl_esgf_day_filenames.csv\", converters={\"filenames\": lambda x: x.strip(\"[]\").split(\", \")})\n",
    "# ignore rows where data not on LLNL node for now\n",
    "df = df.query(\"~n_files.isnull()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae146e-b4ee-4ed8-a773-9df973599696",
   "metadata": {},
   "source": [
    "Define a function to convert rows of that table into tuples of (\\<remote path>, \\<ACDN path>):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c11e413-e487-41a1-98a3-60768c303622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transfer_paths(row):\n",
    "    \"\"\"Generate the paths for transferring between LLNL ESGF node and ACDN\n",
    "    \n",
    "    Args:\n",
    "        row (pandas.core.series.Series): a single row series from pandas.DataFrame.iterrows() on dataframe of desired data filenames\n",
    "    \n",
    "    Returns:\n",
    "        transfer_list (list): has format [(<remote path>, <target path>), ...] for all files in row[\"filenames\"]\n",
    "    \"\"\"\n",
    "    activity = \"CMIP\" if row[\"scenario\"] == \"historical\" else \"ScenarioMIP\"\n",
    "    model = row[\"model\"]\n",
    "    institution = luts.model_inst_lu[model][\"institution\"]\n",
    "    group_path = Path().joinpath(\n",
    "        activity,\n",
    "        institution,\n",
    "        model,\n",
    "        row[\"scenario\"],\n",
    "        row[\"mirror_variant\"],\n",
    "        \"day\",\n",
    "        row[\"variable\"],\n",
    "        row[\"grid_type\"],\n",
    "        row[\"version\"],\n",
    "    )\n",
    "    \n",
    "    transfer_list = []\n",
    "    for fn in row[\"filenames\"]:\n",
    "        fp = group_path.joinpath(fn.replace(\"'\", \"\"))\n",
    "        transfer_list.append((llnl_prefix.joinpath(fp), acdn_prefix.joinpath(fp)))\n",
    "        \n",
    "    return transfer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a75595-1011-4ec1-8f03-55ae3e704dd1",
   "metadata": {},
   "source": [
    "Iterate over variables to create a batch file for each. We're not sure what a reasonable batch size is, so we are arbitrarily going with variable for now. I think the fewert he better if possible.\n",
    "\n",
    "First, define a function to actually write a list of transfer file tuples to a text file for the `--batch` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c28cbe6-c21a-4320-b9ba-4e6c1b6be01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_batch_file(varname, transfer_paths):\n",
    "    \"\"\"Write the batch file for a particular variable and scenario group\"\"\"\n",
    "    batch_file = f\"batch_files/batch_llnl_day_{varname}.txt\"\n",
    "    with open(batch_file, \"w\") as f:\n",
    "        for paths in transfer_paths:\n",
    "            f.write(f\"{paths[0]} {paths[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7102c00-876f-486c-9217-0e090109867e",
   "metadata": {},
   "source": [
    "Now, create the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1d44ecf-53cb-4e91-baba-b57206993ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESGF directory structure convention is /<activity>/<institution>/<model>/<scenario>/<variant>/<frequency>/<variable>/<grid type>/<version>/\n",
    "\n",
    "# get all potential variable names\n",
    "varnames = list(luts.vars_tier1.keys()) + list(luts.vars_tier2.keys())\n",
    "\n",
    "for varname in varnames:\n",
    "    transfer_paths = []\n",
    "    query_str = f\"variable == '{varname}' & scenario == '{scenario}'\"\n",
    "    for row in df.query(query_str).iterrows():\n",
    "        transfer_paths.extend(generate_transfer_paths(row[1]))\n",
    "\n",
    "    write_batch_file(varname, transfer_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ae69b8-af5b-4f53-bfab-91ea4c93874f",
   "metadata": {},
   "source": [
    "batch files should now be in the `batch_files/` folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
