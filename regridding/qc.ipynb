{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3bd18f6-e9e5-43e0-b8a7-73817fdfb282",
   "metadata": {},
   "source": [
    "# Quality control for regridding efforts\n",
    "\n",
    "Use this notebook to check the quality of the regridded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73ab1013-3464-40bb-95bc-03f7f607193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from config import *\n",
    "from regrid import rename_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cadf8cc-8625-402a-ad43-92dc94d0c0ad",
   "metadata": {},
   "source": [
    "### Check for completeness of regridded files\n",
    "\n",
    "Get a list of filepaths for all regridded files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a52bbd-e22d-43c3-a7a9-bf01fa4c7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "regrid_fps = list(regrid_dir.glob(\"*/*/*/*/*.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdc70ce-3801-4b28-97ea-28c843180bc7",
   "metadata": {},
   "source": [
    "Check that all files to be regridded (which are those listed in the batch regrid files) are found in the regrid directory on scratch space.\n",
    "\n",
    "First, need to get all of the source filenames from the batch files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d73eede-9882-4442-ace1-f005a18c85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_fns = []\n",
    "for fp in regrid_batch_dir.glob(\"*.txt\"):\n",
    "    with open(fp) as f:\n",
    "        src_fns.extend([line.split(\"/\")[-1].replace(\"\\n\", \"\") for line in f.readlines()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5ca5d6-0a60-4ebb-876e-5beba0c3f776",
   "metadata": {},
   "source": [
    "Since we renamed the files by replacing the grid type component of the original filename with \"regrid\", we must standardize again for both set of files. Do this by simply dropping \"regrid\" from the regridded files, and dropping the grid type component from the raw filenames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "273bde48-e2e9-4f12-8814-c95d1f858d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = {\"_gr_\": \"_\", \"_gr1_\": \"_\", \"_gn_\": \"_\"}\n",
    "\n",
    "src_fns = set([rename_file(fn, rep) for fn in src_fns])\n",
    "regrid_fns = set([fp.name.replace(\"_regrid_\", \"_\") for fp in regrid_fps])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5f52e-721d-4da5-9725-ade670d3eb42",
   "metadata": {},
   "source": [
    "Now, the source files which are not found in the regridding output directory can be isolated, and the number of them should be equal to the difference in number of files between source and completed files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd6ec1e3-0b0c-4c0f-ae53-f393b3feea85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_fns = list(src_fns - regrid_fns)\n",
    "len(missing_fns) == (len(src_fns) - len(regrid_fns)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57dbe94-055e-4631-93bf-e43d52b41f0c",
   "metadata": {},
   "source": [
    "Sometimes the processing code would create files and fail before writing them completely. Check for file smaller than 1 MB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "037cc7c3-5909-495f-a60f-5b7b6cfee4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 87.2 ms, sys: 123 ms, total: 210 ms\n",
      "Wall time: 35.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def is_smol_file(fp):\n",
    "    \"\"\"Check whether a file is small for a regridded CMIP6 file.\"\"\"\n",
    "    if fp.stat().st_size / (10e2 ** 2) < 1:\n",
    "        return fp\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "with Pool(20) as pool:\n",
    "    smol_fps = pool.map(is_smol_file, regrid_fps)\n",
    "    \n",
    "smol_fps = [fp for fp in smol_fps if fp is not None]\n",
    "\n",
    "assert len(smol_fps) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c909629-b67c-49fd-87e5-8f4421a77d39",
   "metadata": {},
   "source": [
    "### Verify regridding\n",
    "\n",
    "Verify that regridded files all have the target grid.\n",
    "\n",
    "Load the target grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa16c3eb-85d4-46c3-af6a-440cd9eb5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_ds = xr.open_dataset(target_grid_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43980a-df52-479f-b712-0e2e44aa105e",
   "metadata": {},
   "source": [
    "Define a function to check that the lat and lon arrays of the target grid match those of a given regridded fielpath:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f44741fa-9cad-4d66-b241-64d6f99b654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_latlon(regrid_fp, target_lat_arr, target_lon_arr):\n",
    "    assert np.all(regrid_ds[\"lat\"] == target_lat_arr)\n",
    "    assert np.all(regrid_ds[\"lon\"] == target_lon_arr)\n",
    "    \n",
    "    return regrid_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d9a06-7a88-46a4-bc19-e89d7698d9ec",
   "metadata": {},
   "source": [
    "Run the check for all regridded files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5e47979-7232-41d1-86af-ab0c7d6ca077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 467 ms, sys: 163 ms, total: 630 ms\n",
      "Wall time: 849 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_lat_arr = dst_ds[\"lat\"].values\n",
    "target_lon_arr = dst_ds[\"lon\"].values\n",
    "\n",
    "args = [(fp, target_lat_arr, target_lon_arr) for fp in regrid_fps]\n",
    "\n",
    "with Pool(20) as pool:\n",
    "    _ = pool.starmap(verify_latlon, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a27617f-a474-42e2-a69b-1e0f89709f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
