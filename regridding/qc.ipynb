{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe926eb1",
   "metadata": {},
   "source": [
    "## Visual QC notebook\n",
    "This notebook is designed to be used in a visual QC check of regridded CMIP6 data. Regridded files are counted, and a percentage of the files (here 10%) are randomly selected for QC. Using only the output file names, we will:\n",
    "\n",
    "- locate the original CMIP6 source data\n",
    "- plot source data alongside regridded data to compare visually\n",
    "\n",
    "#### How to use with `prefect` via `papermill`:\n",
    "This notebook should be run as the final step of the prefect regridding flow. The output will be saved as a new notebook in the QC directory created during the flow. To accomplish this, create a task in the prefect flow that will execute this notebook from the command line using `papermill`, e.g.:\n",
    "\n",
    "```papermill path/to/repo/regridding/visual_qc.ipynb path/to/qc/output/output.ipynb -r output_directory \"/path/to/output/dir\" -r cmip6_directory \"/path/to/cmip6/dir\"```\n",
    "\n",
    "The first argument is this notebook's location, which can be constructed using the `{output_directory}` parameter of the flow run (ie, the notebook's location within the downloaded repo directory). The second argument is the desired notebook output location, which can also be constructed using the `{output_directory}` parameter of the flow run. The remaining arguments are raw strings (denoted by `-r`) of the working and input directories used in the flow run.\n",
    "\n",
    "Papermill parameter cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f52c02e",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this cell is tagged \"parameters\" and contains default parameter values for this notebook\n",
    "# any parameters injected by papermill during the prefect flow will be written into a new cell directly beneath this one\n",
    "# and will override the values in this cell\n",
    "output_directory = \"/beegfs/CMIP6/snapdata/cmip6_regridding\"\n",
    "cmip6_directory = \"/beegfs/CMIP6/arctic-cmip6/CMIP6\"\n",
    "vars = \"tas\"\n",
    "freqs = \"mon\"\n",
    "models = \"GFDL-ESM4\"\n",
    "scenarios = \"historical\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ab1013-3464-40bb-95bc-03f7f607193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cftime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import random\n",
    "from pandas.errors import OutOfBoundsDatetime\n",
    "from pathlib import Path\n",
    "from config import *\n",
    "from regrid import open_and_crop_dataset, prod_lat_slice, convert_units, get_var_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be44568a",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "Define data sources and parameters for QC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f63ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cmip6_dir\n",
    "cmip6_dir = Path(cmip6_directory)\n",
    "\n",
    "# set regrid_dir and list all *.nc files\n",
    "regrid_directory = output_directory + \"/regrid\"\n",
    "regrid_dir = Path(regrid_directory)\n",
    "\n",
    "regrid_fps = []\n",
    "for model in models.split():\n",
    "    for scenario in scenarios.split():\n",
    "        for var in vars.split():\n",
    "            for freq in freqs.split():\n",
    "                regrid_fps += list(\n",
    "                    regrid_dir.glob(f\"{model}/{scenario}/*{freq}/{var}/*.nc\")\n",
    "                )\n",
    "\n",
    "# set min and max number of files to QC\n",
    "min_qc = 20\n",
    "max_qc = 75\n",
    "\n",
    "# pick a percentage of the regridded files for visual QC, and count those files\n",
    "pct = 10\n",
    "pct_count = round(len(regrid_fps) * (pct / 100))\n",
    "\n",
    "# use all files if less than minimum are available\n",
    "# use max number of random files if percentage exceeds maximum\n",
    "# or just use percentage of random files\n",
    "if len(regrid_fps) <= min_qc:\n",
    "    qc_files = regrid_fps\n",
    "elif pct_count >= max_qc:\n",
    "    qc_files = random.sample(regrid_fps, max_qc)\n",
    "else:\n",
    "    qc_files = random.sample(regrid_fps, pct_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cadf8cc-8625-402a-ad43-92dc94d0c0ad",
   "metadata": {},
   "source": [
    "#### Create functions\n",
    "Here we will build some helper functions to aid us perform a qualitative assessment of the regridding. Using just the regridded file name and the main CMIP6 source directory, we will reconstruct the source file path and by plot a comparison of source files and regridded files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e9636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_time_filepath(fps, test_date):\n",
    "    \"\"\"Find a file from a given list of raw CMIP6 filepaths that conatins the test date within the timespan in the filename.\"\"\"\n",
    "    matching_fps = []\n",
    "    for fp in fps:\n",
    "        start_str, end_str = fp.name.split(\".nc\")[0].split(\"_\")[-1].split(\"-\")\n",
    "        start_str = f\"{start_str}01\" if len(start_str) == 6 else start_str\n",
    "        # end date should be constructed as the end of month for monthly data\n",
    "        #  (and should always be December??)\n",
    "        end_str = f\"{end_str}31\" if len(end_str) == 6 else end_str\n",
    "        format_str = \"%Y%m%d\"\n",
    "        try:\n",
    "            start_dt = pd.to_datetime(start_str, format=format_str)\n",
    "            # it should be OK if end date is\n",
    "            end_dt = pd.to_datetime(end_str, format=format_str)\n",
    "        except OutOfBoundsDatetime:\n",
    "            # we should not be regridding files with time values that cause this (2300 etc)\n",
    "            continue\n",
    "\n",
    "        if start_dt <= test_date < end_dt:\n",
    "            matching_fps.append(fp)\n",
    "\n",
    "    # there should only be one\n",
    "    assert len(matching_fps) == 1\n",
    "\n",
    "    return matching_fps[0]\n",
    "\n",
    "\n",
    "def generate_cmip6_filepath_from_regrid_filename(fn):\n",
    "    \"\"\"Get the path to the original CMIP6 filename from a regridded file name.\n",
    "\n",
    "    Because the original CMIP6 filenames were split up during the processing,\n",
    "    this method finds the original filename based on matching all possible attributes,\n",
    "    then testing for inclusion of regrid file start date within the date range formed by the CMIP6 file timespan.\n",
    "    \"\"\"\n",
    "    var_id, freq, model, scenario, _, timespan = fn.split(\".nc\")[0].split(\"_\")\n",
    "    institution = model_inst_lu[model]\n",
    "    experiment_id = \"ScenarioMIP\" if scenario in prod_scenarios else \"CMIP\"\n",
    "    # Construct the original CMIP6 filepath from the filename.\n",
    "    # Need to use glob because of the \"grid type\" filename attribute that we do not have a lookup for.\n",
    "    var_dir = cmip6_dir.joinpath(f\"{experiment_id}/{institution}/{model}/{scenario}\")\n",
    "    glob_str = f\"*/{freq}/{var_id}/*/*/{var_id}_{freq}_{model}_{scenario}_*.nc\"\n",
    "    candidate_fps = list(var_dir.glob(glob_str))\n",
    "\n",
    "    start_str = timespan.split(\"-\")[0]\n",
    "    format_str = \"%Y%m\" if len(start_str) == 6 else \"%Y%m%d\"\n",
    "    start_dt = pd.to_datetime(start_str, format=format_str)\n",
    "    cmip6_fp = get_matching_time_filepath(candidate_fps, start_dt)\n",
    "\n",
    "    return cmip6_fp\n",
    "\n",
    "\n",
    "def plot_comparison(regrid_fp):\n",
    "    \"\"\"For a given regridded file, find the source file and plot side by side.\"\"\"\n",
    "    src_fp = generate_cmip6_filepath_from_regrid_filename(regrid_fp.name)\n",
    "    src_ds = open_and_crop_dataset(src_fp, lat_slice=prod_lat_slice)\n",
    "    # entire plotting function is inside this try block\n",
    "    # if the dataset cannot be opened, just print a message instead of an error\n",
    "    try:\n",
    "        regrid_ds = xr.open_dataset(regrid_fp)\n",
    "    except:\n",
    "        print(f\"Regridded dataset could not be opened: {regrid_fp}\")\n",
    "\n",
    "    # lat axis is flipped in regrid files\n",
    "    src_lat_slice = slice(55, 75)\n",
    "    regrid_lat_slice = slice(75, 55)\n",
    "    lon_slice_src = slice(200, 240)\n",
    "    lon_slice_regrid = slice(-160, -120)\n",
    "    time_val = regrid_ds.time.values[0]\n",
    "    var_id = src_ds.attrs[\"variable_id\"]\n",
    "    assert get_var_id(src_ds) == var_id, \"Variable ID mismatch\"\n",
    "    assert get_var_id(regrid_ds) == var_id, \"Variable ID mismatch\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
    "\n",
    "    # now, there are multiple possible time formats for the source dataset.\n",
    "    # convert the chosen time value to that matching format for subsetting.\n",
    "    sel_method = None\n",
    "    if isinstance(src_ds.time.values[0], cftime._cftime.Datetime360Day):\n",
    "        # It seems like monthly data use 16 for the day\n",
    "        src_hour = src_ds.time.dt.hour[0]\n",
    "        src_time = cftime.Datetime360Day(\n",
    "            year=time_val.year,\n",
    "            month=time_val.month,\n",
    "            day=time_val.day,\n",
    "            hour=src_hour,\n",
    "        )\n",
    "    elif isinstance(\n",
    "        src_ds.time.values[0], pd._libs.tslibs.timestamps.Timestamp\n",
    "    ) or isinstance(src_ds.time.values[0], np.datetime64):\n",
    "        src_hour = src_ds.time.dt.hour[0].values.item()\n",
    "        src_time = pd.to_datetime(\n",
    "            f\"{time_val.year}-{time_val.month}-{time_val.day}T{src_hour}:00:00\"\n",
    "        )\n",
    "    else:\n",
    "        if time_val not in src_ds.time.values:\n",
    "            src_hour = src_ds.time.dt.hour[0]\n",
    "            src_time = cftime.DatetimeNoLeap(\n",
    "                year=time_val.year,\n",
    "                month=time_val.month,\n",
    "                day=time_val.day,\n",
    "                hour=src_hour,\n",
    "            )\n",
    "        else:\n",
    "            src_time = time_val\n",
    "    if src_time not in src_ds.time.values:\n",
    "        print(f\"Sample timestamp not found in source file ({src_fp}). Using nearest.\")\n",
    "        # probably safe to just use nearest method in any event\n",
    "        # since there can be incorrectly labeled frequency attributes\n",
    "        sel_method = \"nearest\"\n",
    "        if src_ds.attrs[\"frequency\"] == \"mon\":\n",
    "            # We expect that the file will be monthly if the source time chosen is not actually in the dataset\n",
    "            pass\n",
    "        else:\n",
    "            # this is not expected\n",
    "            print(\"Expected monthly file but frequency attribute does not match.\")\n",
    "            assert False\n",
    "\n",
    "    # ensure units are consistent with regridded dataset\n",
    "    src_ds = convert_units(src_ds)\n",
    "\n",
    "    # get a vmin and vmax from src dataset to use for both plots, if a map\n",
    "    try:\n",
    "        vmin = (\n",
    "            src_ds[var_id]\n",
    "            .sel(time=src_time, method=sel_method)\n",
    "            .sel(lat=src_lat_slice, lon=lon_slice_src)\n",
    "            .values.min()\n",
    "        )\n",
    "        vmax = (\n",
    "            src_ds[var_id]\n",
    "            .sel(time=src_time, method=sel_method)\n",
    "            .sel(lat=src_lat_slice, lon=lon_slice_src)\n",
    "            .values.max()\n",
    "        )\n",
    "    except:\n",
    "        print(\"Error getting vmin and vmax values from source data.\")\n",
    "\n",
    "    try:  # maps\n",
    "        src_ds[var_id].sel(time=src_time, method=sel_method).sel(\n",
    "            lat=src_lat_slice, lon=lon_slice_src\n",
    "        ).plot(ax=axes[0], vmin=vmin, vmax=vmax)\n",
    "        axes[0].set_title(f\"Source dataset (timestamp: {src_time})\")\n",
    "        regrid_ds[var_id].sel(time=time_val).sel(\n",
    "            lat=regrid_lat_slice,\n",
    "            lon=lon_slice_regrid,\n",
    "            # explitictly set the x axis to be the standard longitude for regridded data\n",
    "            #  because grid is (confusingly) oriented time, lon, lat for rasdaman\n",
    "        ).plot(ax=axes[1], vmin=vmin, vmax=vmax, x=\"lon\")\n",
    "        axes[1].set_title(f\"Regridded dataset (timestamp: {time_val})\")\n",
    "        axes[1].set_xlabel(\"longitude [standard]\")\n",
    "        plt.show()\n",
    "\n",
    "    except:  # histograms\n",
    "        src_ds[var_id].sel(time=src_time, method=sel_method).sel(\n",
    "            lat=src_lat_slice, lon=lon_slice_src\n",
    "        ).plot(ax=axes[0])\n",
    "        axes[0].set_title(f\"Source dataset (timestamp: {src_time})\")\n",
    "        regrid_ds[var_id].sel(time=time_val).sel(\n",
    "            lat=regrid_lat_slice, lon=lon_slice_regrid\n",
    "        ).plot(ax=axes[1])\n",
    "        axes[1].set_title(f\"Regridded dataset (timestamp: {time_val})\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"Variable: {var_id}     Model: {src_ds.attrs['source_id']}     Scenario: {src_ds.attrs['experiment_id']}\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d35bf9",
   "metadata": {},
   "source": [
    "From our previous random selection of regridded files to QC, plot comparisons in a spatial domain that includes Alaska and western Canada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4383c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fp in qc_files:\n",
    "    plot_comparison(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d92220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
