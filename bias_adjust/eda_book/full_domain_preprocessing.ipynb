{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full domain QDM analysis: preprocessing\n",
    "\n",
    "This notebook is for preprocessing everything for the full spatial domain quantile delta mapping analysis. This consists of running the QDM bias adjustment algorithm for the full spatial domain of the 4km WRF-downscaled ERA5 data, for multiple values of the following parameters:\n",
    "* `window`: size of grouping window in days\n",
    "* `adapt_freq_thresh`: frequency adaptation threshold, threshold used for \"frequency adaptation\" as described by [Theme√ül et al. 2012](https://doi.org/10.1007/s10584-011-0224-4)\n",
    "* `nquantiles`: number of quantiles to use in the adjustment\n",
    "\n",
    "All other parameters will be held fixed, with default values for `window`, `adapt_freq_thresh`, and `nquantiles` being 31, 0.254 mm/day, and 50, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.3.min.js\", \"https://cdn.holoviz.org/panel/1.6.1/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='5941c414-5508-47cc-bb04-bf8a03d84372'>\n",
       "  <div id=\"a913203d-57bd-4df0-bda7-2386de62ec08\" data-root-id=\"5941c414-5508-47cc-bb04-bf8a03d84372\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"627483ee-27a9-4880-b617-36524119f97a\":{\"version\":\"3.6.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"5941c414-5508-47cc-bb04-bf8a03d84372\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"357a1426-0e58-4e3a-89a2-126b2f6b1c79\",\"attributes\":{\"plot_id\":\"5941c414-5508-47cc-bb04-bf8a03d84372\",\"comm_id\":\"83098b4657cf48a19c857d84a6d41bcf\",\"client_comm_id\":\"3a94f180776d4610befc15f3db0a16e8\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"627483ee-27a9-4880-b617-36524119f97a\",\"roots\":{\"5941c414-5508-47cc-bb04-bf8a03d84372\":\"a913203d-57bd-4df0-bda7-2386de62ec08\"},\"root_ids\":[\"5941c414-5508-47cc-bb04-bf8a03d84372\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "5941c414-5508-47cc-bb04-bf8a03d84372"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = false;\n  const py_version = '3.6.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = true;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# config cell\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import cftime\n",
    "import dask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import Proj\n",
    "from xclim import units, sdba, indices\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import hvplot.xarray\n",
    "import panel as pn\n",
    "import shutil\n",
    "from scipy.stats import cramervonmises_2samp\n",
    "\n",
    "pn.extension(comms=\"vscode\")\n",
    "# for reloading the baeda module which is actively developing\n",
    "import baeda\n",
    "from baeda import (\n",
    "    tmp_window_fn,\n",
    "    tmp_adapt_freq_fn,\n",
    "    tmp_nquantiles_fn,\n",
    "    window_sizes,\n",
    "    adapt_freq_threhsolds,\n",
    "    n_quantiles_list,\n",
    ")\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "reload(baeda)\n",
    "\n",
    "\n",
    "cutoff_time = cftime.DatetimeNoLeap(2015, 1, 1, 0, 0, 0, 0, 0)\n",
    "\n",
    "zarr_dir = Path(\"/center1/CMIP6/kmredilla/cmip6_4km_downscaling/cmip6_zarr\")\n",
    "era5_dir = Path(\"/center1/CMIP6/kmredilla/cmip6_4km_downscaling/era5_zarr\")\n",
    "\n",
    "# tmp dir for writing downscaled data\n",
    "tmp_dir = Path(\"/center1/CMIP6/kmredilla/downscaling/eda\")\n",
    "\n",
    "# era5 precip indicators file\n",
    "era5_idx_fp = tmp_dir.joinpath(\"pridx_era5.zarr\")\n",
    "\n",
    "\n",
    "# default parameter values\n",
    "# indexed by variable id in case we add more variables\n",
    "default_params = {\n",
    "    \"pr\": {\n",
    "        \"window\": 31,\n",
    "        \"adapt_freq_thresh\": \"0.254 mm d-1\",\n",
    "        \"nquantiles\": 50,\n",
    "        \"jitter_under_thresh_value\": \"0.01 mm d-1\",\n",
    "        \"kind\": \"*\",\n",
    "    },\n",
    "    \"tasmax\": {\n",
    "        \"window\": 31,\n",
    "        \"nquantiles\": 50,\n",
    "        \"kind\": \"+\",\n",
    "    },\n",
    "    \"dtr\": {\n",
    "        \"window\": 31,\n",
    "        \"nquantiles\": 50,\n",
    "        \"jitter_under_thresh_value\": \"1e-4 K\",\n",
    "        \"kind\": \"*\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "index_name_lu = {\n",
    "    \"pr\": {\n",
    "        \"rx1day\": \"Max 1-day precip\",\n",
    "        \"rx5day\": \"Max 5-day precip\",\n",
    "        \"cdd\": \"Consecutive dry Days\",\n",
    "        \"cwd\": \"Consecutive wet days\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing\n",
    "\n",
    "This section is for running the downscaling and computing indicators. It saves the output to a temporary directory and so need not be run if outputs for the visualization section already exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Client(n_workers=12, threads_per_worker=2)\n",
    "\n",
    "# for interactive nb testing\n",
    "cluster = SLURMCluster(\n",
    "    cores=28,\n",
    "    processes=14,\n",
    "    # n_workers=14,\n",
    "    memory=\"128GB\",\n",
    "    # queue=\"debug\",\n",
    "    queue=\"t2small\",\n",
    "    # walltime=\"01:00:00\",\n",
    "    walltime=\"12:00:00\",\n",
    "    log_directory=\"/beegfs/CMIP6/kmredilla/tmp/dask_jobqueue_logs\",\n",
    "    account=\"cmip6\",\n",
    "    interface=\"ib0\",\n",
    ")\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big cluster for fast processing!\n",
    "cluster.scale(n=140)\n",
    "\n",
    "# lil cluster for testing\n",
    "# cluster.scale(n=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to ERA5 data\n",
    "era5_stores = {\n",
    "    \"t2max\": era5_dir.joinpath(\"t2max_era5.zarr\"),\n",
    "    \"pr\": era5_dir.joinpath(\"pr_era5.zarr\"),\n",
    "}\n",
    "\n",
    "era5_ds = baeda.open_era5_dataset(era5_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing ERA5 indicators data store (/center1/CMIP6/kmredilla/downscaling/eda/pridx_era5.zarr)\n"
     ]
    }
   ],
   "source": [
    "# run ERA5 indicators\n",
    "def run_era5_indicators():\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # not able to silence large graph threshold warnings\n",
    "        era5_idx = baeda.run_indicators(era5_ds[var_id], indices=[\"rx1day\", \"dpi\"])\n",
    "        shutil.rmtree(era5_idx_fp, ignore_errors=True)\n",
    "        _ = era5_idx.to_zarr(era5_idx_fp)\n",
    "\n",
    "\n",
    "var_id = \"pr\"\n",
    "if era5_idx_fp.exists():\n",
    "    if (\n",
    "        input(f\"Delete existing ERA5 indicators data store ({era5_idx_fp})? (y/n)\")\n",
    "        == \"y\"\n",
    "    ):\n",
    "        run_era5_indicators()\n",
    "    else:\n",
    "        print(f\"Using existing ERA5 indicators data store ({era5_idx_fp})\")\n",
    "        era5_idx = xr.open_zarr(era5_idx_fp)\n",
    "else:\n",
    "    run_era5_indicators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and adjust for three different window sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window profiling funcs\n",
    "def run_window_adjustments(\n",
    "    model, scenario, var_id, zarr_dir, era5_ds, tmp_dir, window_sizes, no_clobber=True\n",
    "):\n",
    "    print(\n",
    "        \"Running historical adjustments for different window sizes for model: \", model\n",
    "    )\n",
    "    hist, sim = baeda.extract_time_series_from_zarr(\n",
    "        zarr_dir, model, scenario, var_id, coords=None\n",
    "    )\n",
    "\n",
    "    # QDM: train the adjustment\n",
    "    # rechunking to allow for more workers\n",
    "    chunk_kwargs = {\"time\": -1, \"x\": 10, \"y\": 10}\n",
    "    train_kwargs = dict(\n",
    "        ref=era5_ds[var_id].chunk(**chunk_kwargs),\n",
    "        # think having experiment coordinate may quietly prevent\n",
    "        # adjustment of data with different coordinates (e.g. ssp's)\n",
    "        hist=hist.chunk(**chunk_kwargs)\n",
    "        .isel(Method=0, experiment=0)\n",
    "        .drop_vars([\"Method\", \"experiment\"]),\n",
    "        group=\"time.dayofyear\",\n",
    "        **default_params[var_id],\n",
    "    )\n",
    "\n",
    "    for window in window_sizes:\n",
    "        # skipping if exists for now\n",
    "        out_fp = tmp_dir.joinpath(\n",
    "            tmp_window_fn.format(\n",
    "                qm_window=window,\n",
    "                var_id=var_id,\n",
    "                model=model,\n",
    "                scenario=\"historical\",\n",
    "            )\n",
    "        )\n",
    "        if out_fp.exists() & no_clobber:\n",
    "            print(\"Skipping existing zarr store: \", out_fp)\n",
    "            continue\n",
    "\n",
    "        train_kwargs.update(\n",
    "            window=window,\n",
    "        )\n",
    "        print(f\"Training with window: {window}\")\n",
    "\n",
    "        qdm_train = sdba.QuantileDeltaMapping.train(**train_kwargs)\n",
    "\n",
    "        hist_adj = (\n",
    "            qdm_train.adjust(\n",
    "                hist.chunk(**chunk_kwargs),\n",
    "                extrapolation=\"constant\",\n",
    "                interp=\"nearest\",\n",
    "            )\n",
    "            .isel(Method=0, drop=True)\n",
    "            .assign_coords(window=window)\n",
    "            .expand_dims(\"window\")\n",
    "            .transpose(\"window\", \"experiment\", \"time\", \"y\", \"x\")\n",
    "        )\n",
    "        hist_adj.name = var_id\n",
    "\n",
    "        # compute\n",
    "        hist_adj = hist_adj.load()\n",
    "\n",
    "        # write\n",
    "        out_fp = tmp_dir.joinpath(\n",
    "            tmp_window_fn.format(\n",
    "                qm_window=window,\n",
    "                var_id=var_id,\n",
    "                model=model,\n",
    "                scenario=\"historical\",\n",
    "            )\n",
    "        )\n",
    "        if out_fp.exists():\n",
    "            print(\"Deleting existing zarr store: \", out_fp)\n",
    "            shutil.rmtree(out_fp, ignore_errors=True)\n",
    "        hist_adj.to_dataset().to_zarr(out_fp)\n",
    "\n",
    "\n",
    "def run_historical_window_indicators(\n",
    "    model, var_id, tmp_dir, window_sizes, no_clobber=True\n",
    "):\n",
    "    print(\"Running historical indicators for different window sizes for model: \", model)\n",
    "\n",
    "    for window in window_sizes:\n",
    "        hist_idx_fp = tmp_dir.joinpath(\n",
    "            tmp_window_fn.format(\n",
    "                qm_window=window,\n",
    "                var_id=var_id + \"idx\",\n",
    "                model=model,\n",
    "                scenario=\"historical\",\n",
    "            )\n",
    "        )\n",
    "        if hist_idx_fp.exists() & no_clobber:\n",
    "            print(\"Skipping existing zarr store: \", hist_idx_fp)\n",
    "            continue\n",
    "\n",
    "        hist_adj = xr.open_zarr(\n",
    "            tmp_dir.joinpath(\n",
    "                tmp_window_fn.format(\n",
    "                    qm_window=window,\n",
    "                    var_id=var_id,\n",
    "                    model=model,\n",
    "                    scenario=\"historical\",\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        hist_idx = baeda.run_indicators(\n",
    "            hist_adj[var_id].load(), indices=[\"rx1day\", \"dpi\"]\n",
    "        )\n",
    "\n",
    "        if hist_idx_fp.exists():\n",
    "            print(\"Deleting existing zarr store: \", hist_idx_fp)\n",
    "            shutil.rmtree(hist_idx_fp, ignore_errors=True)\n",
    "        hist_idx.to_zarr(hist_idx_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running historical adjustments for different window sizes for model:  GFDL-ESM4\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw31_pr_GFDL-ESM4_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw45_pr_GFDL-ESM4_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw61_pr_GFDL-ESM4_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw91_pr_GFDL-ESM4_historical.zarr\n",
      "Running historical adjustments for different window sizes for model:  NorESM2-MM\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw31_pr_NorESM2-MM_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw45_pr_NorESM2-MM_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw61_pr_NorESM2-MM_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw91_pr_NorESM2-MM_historical.zarr\n",
      "Running historical adjustments for different window sizes for model:  EC-Earth3-Veg\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw31_pr_EC-Earth3-Veg_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw45_pr_EC-Earth3-Veg_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw61_pr_EC-Earth3-Veg_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw91_pr_EC-Earth3-Veg_historical.zarr\n"
     ]
    }
   ],
   "source": [
    "scenario = \"ssp585\"\n",
    "var_id = \"pr\"\n",
    "\n",
    "for model in [\"GFDL-ESM4\", \"NorESM2-MM\", \"EC-Earth3-Veg\"]:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        run_window_adjustments(\n",
    "            model, scenario, var_id, zarr_dir, era5_ds, tmp_dir, window_sizes\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running historical indicators for different window sizes for model:  GFDL-ESM4\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw31_pridx_GFDL-ESM4_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw45_pridx_GFDL-ESM4_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw61_pridx_GFDL-ESM4_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw91_pridx_GFDL-ESM4_historical.zarr\n",
      "Running historical indicators for different window sizes for model:  NorESM2-MM\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw31_pridx_NorESM2-MM_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw45_pridx_NorESM2-MM_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw61_pridx_NorESM2-MM_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw91_pridx_NorESM2-MM_historical.zarr\n",
      "Running historical indicators for different window sizes for model:  EC-Earth3-Veg\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw31_pridx_EC-Earth3-Veg_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw45_pridx_EC-Earth3-Veg_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw61_pridx_EC-Earth3-Veg_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/qmw91_pridx_EC-Earth3-Veg_historical.zarr\n"
     ]
    }
   ],
   "source": [
    "scenario = \"ssp585\"\n",
    "var_id = \"pr\"\n",
    "\n",
    "for model in [\"GFDL-ESM4\", \"NorESM2-MM\", \"EC-Earth3-Veg\"]:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        run_historical_window_indicators(\n",
    "            model, var_id, tmp_dir, window_sizes, no_clobber=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_adapt_freq_adjustments(\n",
    "    model,\n",
    "    scenario,\n",
    "    var_id,\n",
    "    zarr_dir,\n",
    "    era5_ds,\n",
    "    tmp_dir,\n",
    "    adapt_freq_threhsolds,\n",
    "    no_clobber=True,\n",
    "):\n",
    "    print(\"Running historical adjustments for adapt_freq thresholds for model: \", model)\n",
    "    hist, sim = baeda.extract_time_series_from_zarr(\n",
    "        zarr_dir, model, scenario, var_id, coords=None\n",
    "    )\n",
    "\n",
    "    # QDM: train the adjustment\n",
    "    # rechunking to allow for more workers\n",
    "    chunk_kwargs = {\"time\": -1, \"x\": 10, \"y\": 10}\n",
    "    train_kwargs = dict(\n",
    "        ref=era5_ds[var_id].chunk(**chunk_kwargs),\n",
    "        # think having experiment coordinate may quietly prevent\n",
    "        # adjustment of data with different coordinates (e.g. ssp's)\n",
    "        hist=hist.chunk(**chunk_kwargs)\n",
    "        .isel(Method=0, experiment=0)\n",
    "        .drop_vars([\"Method\", \"experiment\"]),\n",
    "        group=\"time.dayofyear\",\n",
    "        **default_params[var_id],\n",
    "    )\n",
    "\n",
    "    for thresh in adapt_freq_threhsolds:\n",
    "        out_fp = tmp_dir.joinpath(\n",
    "            tmp_adapt_freq_fn.format(\n",
    "                adapt_freq=thresh.replace(\" \", \"\"),\n",
    "                var_id=var_id,\n",
    "                model=model,\n",
    "                scenario=\"historical\",\n",
    "            )\n",
    "        )\n",
    "        if out_fp.exists() & no_clobber:\n",
    "            print(\"Skipping existing zarr store: \", out_fp)\n",
    "            continue\n",
    "\n",
    "        train_kwargs.update(\n",
    "            adapt_freq_thresh=thresh,\n",
    "        )\n",
    "        print(f\"Training with adapt_freq threhsold of: {thresh}\")\n",
    "\n",
    "        qdm_train = sdba.QuantileDeltaMapping.train(**train_kwargs)\n",
    "\n",
    "        hist_adj = (\n",
    "            qdm_train.adjust(\n",
    "                hist.chunk(**chunk_kwargs),\n",
    "                extrapolation=\"constant\",\n",
    "                interp=\"nearest\",\n",
    "            )\n",
    "            .isel(Method=0, drop=True)\n",
    "            .assign_coords(adapt_freq=thresh)\n",
    "            .expand_dims(\"adapt_freq\")\n",
    "            .transpose(\"adapt_freq\", \"experiment\", \"time\", \"y\", \"x\")\n",
    "        )\n",
    "        hist_adj.name = var_id\n",
    "\n",
    "        # compute\n",
    "        hist_adj = hist_adj.load()\n",
    "\n",
    "        # write\n",
    "        if out_fp.exists():\n",
    "            print(\"Deleting existing zarr store: \", out_fp)\n",
    "            shutil.rmtree(out_fp, ignore_errors=True)\n",
    "        hist_adj.to_dataset().to_zarr(out_fp)\n",
    "\n",
    "\n",
    "def run_historical_adapt_freq_indicators(\n",
    "    model, var_id, tmp_dir, adapt_freq_threhsolds, no_clobber=True\n",
    "):\n",
    "    print(\"Running historical indicators for adapt_freq thresholds for model: \", model)\n",
    "    for adapt_freq in adapt_freq_threhsolds:\n",
    "        hist_idx_fp = tmp_dir.joinpath(\n",
    "            tmp_adapt_freq_fn.format(\n",
    "                adapt_freq=adapt_freq.replace(\" \", \"\"),\n",
    "                var_id=var_id + \"idx\",\n",
    "                model=model,\n",
    "                scenario=\"historical\",\n",
    "            )\n",
    "        )\n",
    "        if hist_idx_fp.exists() & no_clobber:\n",
    "            print(\"Skipping existing zarr store: \", hist_idx_fp)\n",
    "            continue\n",
    "\n",
    "        hist_adj_fp = tmp_dir.joinpath(\n",
    "            tmp_adapt_freq_fn.format(\n",
    "                adapt_freq=adapt_freq.replace(\" \", \"\"),\n",
    "                var_id=var_id,\n",
    "                model=model,\n",
    "                scenario=\"historical\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        hist_adj = xr.open_zarr(hist_adj_fp)\n",
    "        hist_idx = baeda.run_indicators(\n",
    "            hist_adj[var_id].load(), indices=[\"rx1day\", \"dpi\"]\n",
    "        )\n",
    "\n",
    "        if hist_idx_fp.exists():\n",
    "            print(\"Deleting existing zarr store: \", hist_idx_fp)\n",
    "            shutil.rmtree(hist_idx_fp, ignore_errors=True)\n",
    "        hist_idx.to_zarr(hist_idx_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running historical adjustments for adapt_freq thresholds for model:  GFDL-ESM4\n",
      "Training with adapt_freq threhsold of: 0.05 mm d-1\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/0.05mmd-1_pr_GFDL-ESM4_historical.zarr\n",
      "Training with adapt_freq threhsold of: 0.254 mm d-1\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/0.254mmd-1_pr_GFDL-ESM4_historical.zarr\n",
      "Training with adapt_freq threhsold of: 1 mm d-1\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/1mmd-1_pr_GFDL-ESM4_historical.zarr\n",
      "Training with adapt_freq threhsold of: 2 mm d-1\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/2mmd-1_pr_GFDL-ESM4_historical.zarr\n",
      "Running historical adjustments for adapt_freq thresholds for model:  NorESM2-MM\n",
      "Training with adapt_freq threhsold of: 0.05 mm d-1\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/0.05mmd-1_pr_NorESM2-MM_historical.zarr\n",
      "Training with adapt_freq threhsold of: 0.254 mm d-1\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/0.254mmd-1_pr_NorESM2-MM_historical.zarr\n",
      "Training with adapt_freq threhsold of: 1 mm d-1\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/1mmd-1_pr_NorESM2-MM_historical.zarr\n",
      "Training with adapt_freq threhsold of: 2 mm d-1\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/2mmd-1_pr_NorESM2-MM_historical.zarr\n",
      "Running historical adjustments for adapt_freq thresholds for model:  EC-Earth3-Veg\n",
      "Training with adapt_freq threhsold of: 0.05 mm d-1\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/0.05mmd-1_pr_EC-Earth3-Veg_historical.zarr\n",
      "Training with adapt_freq threhsold of: 0.254 mm d-1\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/0.254mmd-1_pr_EC-Earth3-Veg_historical.zarr\n",
      "Training with adapt_freq threhsold of: 1 mm d-1\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/1mmd-1_pr_EC-Earth3-Veg_historical.zarr\n",
      "Training with adapt_freq threhsold of: 2 mm d-1\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/2mmd-1_pr_EC-Earth3-Veg_historical.zarr\n"
     ]
    }
   ],
   "source": [
    "scenario = \"ssp585\"\n",
    "var_id = \"pr\"\n",
    "\n",
    "for model in [\"GFDL-ESM4\", \"NorESM2-MM\", \"EC-Earth3-Veg\"]:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        run_adapt_freq_adjustments(\n",
    "            model,\n",
    "            scenario,\n",
    "            var_id,\n",
    "            zarr_dir,\n",
    "            era5_ds,\n",
    "            tmp_dir,\n",
    "            adapt_freq_threhsolds,\n",
    "            no_clobber=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running historical indicators for adapt_freq thresholds for model:  GFDL-ESM4\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/0.05mmd-1_pridx_GFDL-ESM4_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/0.254mmd-1_pridx_GFDL-ESM4_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/1mmd-1_pridx_GFDL-ESM4_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/2mmd-1_pridx_GFDL-ESM4_historical.zarr\n",
      "Running historical indicators for adapt_freq thresholds for model:  NorESM2-MM\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/0.05mmd-1_pridx_NorESM2-MM_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/0.254mmd-1_pridx_NorESM2-MM_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/1mmd-1_pridx_NorESM2-MM_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/2mmd-1_pridx_NorESM2-MM_historical.zarr\n",
      "Running historical indicators for adapt_freq thresholds for model:  EC-Earth3-Veg\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/0.05mmd-1_pridx_EC-Earth3-Veg_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/0.254mmd-1_pridx_EC-Earth3-Veg_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/1mmd-1_pridx_EC-Earth3-Veg_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/2mmd-1_pridx_EC-Earth3-Veg_historical.zarr\n"
     ]
    }
   ],
   "source": [
    "scenario = \"ssp585\"\n",
    "var_id = \"pr\"\n",
    "\n",
    "for model in [\"GFDL-ESM4\", \"NorESM2-MM\", \"EC-Earth3-Veg\"]:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        run_historical_adapt_freq_indicators(\n",
    "            model, var_id, tmp_dir, adapt_freq_threhsolds, no_clobber=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_quantile_adjustments(\n",
    "    model,\n",
    "    scenario,\n",
    "    var_id,\n",
    "    zarr_dir,\n",
    "    era5_ds,\n",
    "    tmp_dir,\n",
    "    n_quantiles_list,\n",
    "    no_clobber=True,\n",
    "):\n",
    "    print(\n",
    "        \"Running historical adjustments for different numbers of quantiles for model: \",\n",
    "        model,\n",
    "    )\n",
    "    hist, sim = baeda.extract_time_series_from_zarr(\n",
    "        zarr_dir, model, scenario, var_id, coords=None\n",
    "    )\n",
    "\n",
    "    # QDM: train the adjustment\n",
    "    # rechunking to allow for more workers\n",
    "    chunk_kwargs = {\"time\": -1, \"x\": 10, \"y\": 10}\n",
    "    train_kwargs = dict(\n",
    "        ref=era5_ds[var_id].chunk(**chunk_kwargs),\n",
    "        # think having experiment coordinate may quietly prevent\n",
    "        # adjustment of data with different coordinates (e.g. ssp's)\n",
    "        hist=hist.chunk(**chunk_kwargs)\n",
    "        .isel(Method=0, experiment=0)\n",
    "        .drop_vars([\"Method\", \"experiment\"]),\n",
    "        group=\"time.dayofyear\",\n",
    "        **default_params[var_id],\n",
    "    )\n",
    "\n",
    "    for nquantiles in n_quantiles_list:\n",
    "        out_fp = tmp_dir.joinpath(\n",
    "            tmp_nquantiles_fn.format(\n",
    "                nquantiles=nquantiles,\n",
    "                var_id=var_id,\n",
    "                model=model,\n",
    "                scenario=\"historical\",\n",
    "            )\n",
    "        )\n",
    "        if out_fp.exists() & no_clobber:\n",
    "            print(\"Skipping existing zarr store: \", out_fp)\n",
    "            continue\n",
    "\n",
    "        train_kwargs.update(\n",
    "            nquantiles=nquantiles,\n",
    "        )\n",
    "        print(f\"Training with nquantiles: {nquantiles}\")\n",
    "\n",
    "        qdm_train = sdba.QuantileDeltaMapping.train(**train_kwargs)\n",
    "\n",
    "        hist_adj = (\n",
    "            qdm_train.adjust(\n",
    "                hist.chunk(**chunk_kwargs),\n",
    "                extrapolation=\"constant\",\n",
    "                interp=\"nearest\",\n",
    "            )\n",
    "            .isel(Method=0, drop=True)\n",
    "            .assign_coords(nquantiles=nquantiles)\n",
    "            .expand_dims(\"nquantiles\")\n",
    "            .transpose(\"nquantiles\", \"experiment\", \"time\", \"y\", \"x\")\n",
    "        )\n",
    "        hist_adj.name = var_id\n",
    "\n",
    "        # compute\n",
    "        hist_adj = hist_adj.load()\n",
    "\n",
    "        if out_fp.exists():\n",
    "            print(\"Deleting existing zarr store: \", out_fp)\n",
    "            shutil.rmtree(out_fp, ignore_errors=True)\n",
    "        hist_adj.to_dataset().to_zarr(out_fp)\n",
    "\n",
    "\n",
    "def run_historical_quantile_indicators(\n",
    "    model, var_id, tmp_dir, n_quantiles_list, no_clobber=True\n",
    "):\n",
    "    print(\"Running historical indicators for different nquantiles for model: \", model)\n",
    "    for nquantiles in n_quantiles_list:\n",
    "        hist_idx_fp = tmp_dir.joinpath(\n",
    "            tmp_nquantiles_fn.format(\n",
    "                nquantiles=nquantiles,\n",
    "                var_id=var_id + \"idx\",\n",
    "                model=model,\n",
    "                scenario=\"historical\",\n",
    "            )\n",
    "        )\n",
    "        if hist_idx_fp.exists() & no_clobber:\n",
    "            print(\"Skipping existing zarr store: \", hist_idx_fp)\n",
    "            continue\n",
    "\n",
    "        hist_adj_fp = tmp_dir.joinpath(\n",
    "            tmp_nquantiles_fn.format(\n",
    "                nquantiles=nquantiles,\n",
    "                var_id=var_id,\n",
    "                model=model,\n",
    "                scenario=\"historical\",\n",
    "            )\n",
    "        )\n",
    "        hist_adj = xr.open_zarr(hist_adj_fp)\n",
    "        hist_idx = baeda.run_indicators(hist_adj[var_id], indices=[\"rx1day\", \"dpi\"])\n",
    "\n",
    "        if hist_idx_fp.exists():\n",
    "            print(\"Deleting existing zarr store: \", hist_idx_fp)\n",
    "            shutil.rmtree(hist_idx_fp, ignore_errors=True)\n",
    "        hist_idx.to_zarr(hist_idx_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running historical adjustments for different numbers of quantiles for model:  GFDL-ESM4\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq50_pr_GFDL-ESM4_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq100_pr_GFDL-ESM4_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq150_pr_GFDL-ESM4_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq200_pr_GFDL-ESM4_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq250_pr_GFDL-ESM4_historical.zarr\n",
      "Running historical adjustments for different numbers of quantiles for model:  NorESM2-MM\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq50_pr_NorESM2-MM_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq100_pr_NorESM2-MM_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq150_pr_NorESM2-MM_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq200_pr_NorESM2-MM_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq250_pr_NorESM2-MM_historical.zarr\n",
      "Running historical adjustments for different numbers of quantiles for model:  EC-Earth3-Veg\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq50_pr_EC-Earth3-Veg_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq100_pr_EC-Earth3-Veg_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq150_pr_EC-Earth3-Veg_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq200_pr_EC-Earth3-Veg_historical.zarr\n",
      "Skipping existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq250_pr_EC-Earth3-Veg_historical.zarr\n"
     ]
    }
   ],
   "source": [
    "scenario = \"ssp585\"\n",
    "var_id = \"pr\"\n",
    "\n",
    "for model in [\"GFDL-ESM4\", \"NorESM2-MM\", \"EC-Earth3-Veg\"]:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        run_quantile_adjustments(\n",
    "            model, scenario, var_id, zarr_dir, era5_ds, tmp_dir, n_quantiles_list\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running historical indicators for different nquantiles for model:  GFDL-ESM4\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq50_pridx_GFDL-ESM4_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq100_pridx_GFDL-ESM4_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq150_pridx_GFDL-ESM4_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq200_pridx_GFDL-ESM4_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq250_pridx_GFDL-ESM4_historical.zarr\n",
      "Running historical indicators for different nquantiles for model:  NorESM2-MM\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq50_pridx_NorESM2-MM_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq100_pridx_NorESM2-MM_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq150_pridx_NorESM2-MM_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq200_pridx_NorESM2-MM_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq250_pridx_NorESM2-MM_historical.zarr\n",
      "Running historical indicators for different nquantiles for model:  EC-Earth3-Veg\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq50_pridx_EC-Earth3-Veg_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq100_pridx_EC-Earth3-Veg_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq150_pridx_EC-Earth3-Veg_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq200_pridx_EC-Earth3-Veg_historical.zarr\n",
      "Deleting existing zarr store:  /center1/CMIP6/kmredilla/downscaling/eda/nq250_pridx_EC-Earth3-Veg_historical.zarr\n"
     ]
    }
   ],
   "source": [
    "scenario = \"ssp585\"\n",
    "var_id = \"pr\"\n",
    "\n",
    "for model in [\"GFDL-ESM4\", \"NorESM2-MM\", \"EC-Earth3-Veg\"]:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        run_historical_quantile_indicators(\n",
    "            model, var_id, tmp_dir, n_quantiles_list, no_clobber=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cramer-von Mises calculations\n",
    "\n",
    "Conduct the pixelwise Cramer-von Mises tests for all adjusted datasets and write to the `tmp_dir`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the pixelwise Cramer von mises test for the Rx1day indicator\n",
    "# for the different frequency adaptation thresholds and combine\n",
    "\n",
    "\n",
    "def run_cvm(iter, keyname, models, var_id, tmp_dir, tmp_fn, era5_idx, indicators):\n",
    "    cvm_datasets = []\n",
    "    for i in iter:\n",
    "        for model in models:\n",
    "            fn_format_di = {\n",
    "                keyname: str(i).replace(\" \", \"\"),\n",
    "                \"var_id\": var_id + \"idx\",\n",
    "                \"model\": model,\n",
    "                \"scenario\": \"historical\",\n",
    "            }\n",
    "            hist_idx = xr.open_zarr(\n",
    "                tmp_dir.joinpath(\n",
    "                    tmp_fn.format(\n",
    "                        **fn_format_di,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            hist_idx.load()\n",
    "            hist_idx = hist_idx.assign_coords(model=model).expand_dims(\"model\")\n",
    "\n",
    "            for indicator in indicators:\n",
    "                cvm = cramervonmises_2samp(\n",
    "                    hist_idx[indicator].values.squeeze(),\n",
    "                    era5_idx[indicator].values.squeeze(),\n",
    "                    method=\"asymptotic\",\n",
    "                )\n",
    "\n",
    "                dims = {\n",
    "                    dim: size for dim, size in hist_idx.sizes.items() if dim != \"time\"\n",
    "                }\n",
    "                new_ds = xr.Dataset(\n",
    "                    {\n",
    "                        f\"{indicator}_pval\": (\n",
    "                            dims.keys(),\n",
    "                            np.expand_dims(cvm.pvalue, axis=[0, 1, 2]),\n",
    "                        ),\n",
    "                    },\n",
    "                    coords={dim: hist_idx.coords[dim] for dim in dims.keys()},\n",
    "                )\n",
    "                cvm_datasets.append(new_ds)\n",
    "\n",
    "    cvm_ds = xr.merge(cvm_datasets)\n",
    "\n",
    "    fn_format_di.update(\n",
    "        {keyname: keyname, \"var_id\": var_id + \"idx_cvm\", \"model\": \"allmodels\"}\n",
    "    )\n",
    "    cvm_fp = tmp_dir.joinpath(\n",
    "        tmp_fn.format(\n",
    "            **fn_format_di,\n",
    "        )\n",
    "    )\n",
    "    if cvm_fp.exists():\n",
    "        print(\"Deleting existing zarr store: \", cvm_fp)\n",
    "        shutil.rmtree(cvm_fp, ignore_errors=True)\n",
    "    cvm_ds.to_zarr(cvm_fp)\n",
    "\n",
    "    return cvm_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window sizes Cramer-von mises tests\n",
    "iter = window_sizes\n",
    "fn_key = \"qm_window\"\n",
    "tmp_fn = tmp_window_fn\n",
    "models = [\"GFDL-ESM4\", \"NorESM2-MM\", \"EC-Earth3-Veg\"]\n",
    "indicators = [\"rx1day\", \"dpi\"]\n",
    "\n",
    "\n",
    "window_cvm = run_cvm(\n",
    "    iter=iter,\n",
    "    keyname=fn_key,\n",
    "    models=models,\n",
    "    var_id=var_id,\n",
    "    tmp_dir=tmp_dir,\n",
    "    tmp_fn=tmp_fn,\n",
    "    era5_idx=era5_idx,\n",
    "    indicators=indicators,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency adaptation Cramer-von mises tests\n",
    "iter = adapt_freq_threhsolds\n",
    "fn_key = \"adapt_freq\"\n",
    "tmp_fn = tmp_adapt_freq_fn\n",
    "models = [\"GFDL-ESM4\", \"NorESM2-MM\", \"EC-Earth3-Veg\"]\n",
    "indicators = [\"rx1day\", \"dpi\"]\n",
    "\n",
    "\n",
    "adapt_freq_cvm = run_cvm(\n",
    "    iter=iter,\n",
    "    keyname=fn_key,\n",
    "    models=models,\n",
    "    var_id=var_id,\n",
    "    tmp_dir=tmp_dir,\n",
    "    tmp_fn=tmp_fn,\n",
    "    era5_idx=era5_idx,\n",
    "    indicators=indicators,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nquantiles Cramer-von mises tests\n",
    "iter = n_quantiles_list\n",
    "fn_key = \"nquantiles\"\n",
    "tmp_fn = tmp_nquantiles_fn\n",
    "models = [\"GFDL-ESM4\", \"NorESM2-MM\", \"EC-Earth3-Veg\"]\n",
    "indicators = [\"rx1day\", \"dpi\"]\n",
    "\n",
    "\n",
    "nquantiles_cvm = run_cvm(\n",
    "    iter=iter,\n",
    "    keyname=fn_key,\n",
    "    models=models,\n",
    "    var_id=var_id,\n",
    "    tmp_dir=tmp_dir,\n",
    "    tmp_fn=tmp_fn,\n",
    "    era5_idx=era5_idx,\n",
    "    indicators=indicators,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
